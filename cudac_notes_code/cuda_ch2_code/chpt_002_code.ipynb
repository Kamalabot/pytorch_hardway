{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mVgKXIF-zX-",
        "outputId": "13202b11-e769-4f55-cf5d-4e9c8355fa9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-23 10:26:06--  https://raw.githubusercontent.com/Kamalabot/pytorch_hardway/main/cudac_notes_code/cuda_ch2_code/list2_8/deviceInfo.cu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3305 (3.2K) [text/plain]\n",
            "Saving to: ‘deviceInfo.cu’\n",
            "\n",
            "deviceInfo.cu       100%[===================>]   3.23K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-05-23 10:26:06 (37.6 MB/s) - ‘deviceInfo.cu’ saved [3305/3305]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/Kamalabot/pytorch_hardway/main/cudac_notes_code/cuda_ch2_code/list2_8/deviceInfo.cu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!which nvcc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDdnuVCb_KBP",
        "outputId": "8ef31ee9-03f0-457e-98e9-4b6a591e7014"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/cuda/bin/nvcc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRyfdbLu_TPC",
        "outputId": "73057c39-14d7-4e3e-dc22-e874d7942c82"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fl11ZJRW_J_B",
        "outputId": "b5716e14-2d63-4903-abd3-4d88b72edcaa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deviceInfo.cu  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!g++ --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-A9m2S93_J8l",
        "outputId": "4a0102b9-09fb-459d-eebc-79a0eef951d5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "Copyright (C) 2021 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deviceInfo.cu\n",
        "\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "using namespace std;\n",
        "\n",
        "int main(){\n",
        "    int devCount = 0;\n",
        "    cudaError_t error_id = cudaGetDeviceCount(&devCount);\n",
        "\n",
        "    if (error_id != cudaSuccess){\n",
        "        cout << \"Cuda device count returned: \" << \"Error id: \" << error_id << \"Error: \" << cudaGetErrorString(error_id) << endl;\n",
        "        cout << \"Result: Failed\" << endl;\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    if (devCount == 0){\n",
        "        cout << \"There is no available device that support CUDA\" << endl;\n",
        "    } else {\n",
        "        cout << \"Detected device-\" << devCount << \" CUDA compatible device\" << endl;\n",
        "    }\n",
        "\n",
        "    int dev, driverVersion = 0, runtimeVersion = 0;\n",
        "\n",
        "    dev = 0;\n",
        "    cudaSetDevice(dev);\n",
        "    cudaDeviceProp deviceProp;\n",
        "    cudaGetDeviceProperties(&deviceProp, dev)\n",
        "\n",
        "    cout << \"Device no: \" << dev << \" and Device Name: \" << deviceProp.name;\n",
        "\n",
        "    cudaDriverGetVersion(&driverVersion);  // gets the driver version\n",
        "    cudaRuntimeGetVersion(&runtimeVersion);  // gets runtime version\n",
        "\n",
        "    cout << \"Cuda Driver Version \" << driverVersion / 1000 << \".\" << (driverVersion % 100) / 10 << endl;\n",
        "    cout << \"Runtime Version \" << runtimeVersion / 1000 << \".\" << (runtimeVersion % 100) / 10 << endl;\n",
        "\n",
        "    cout << \"Cuda Capability: Major version \" << deviceProp.major << \" Minor Version: \" << deviceProp.minor << endl;\n",
        "\n",
        "    cout << \"Total Amount of Global Memory: \" << deviceProp.totalGlobalMem / (pow(1024.0, 3)) << \" MBytes\" << endl;\n",
        "\n",
        "    cout << \"Max Multi-processor: \" << deviceProp.multiProcessorCount << endl;\n",
        "\n",
        "    cout << \"GPU Clock Rate: \" << deviceProp.clockRate * 1e-3f << endl;\n",
        "\n",
        "    cout << \"Memory Clock Rate: \" << deviceProp.memoryClockRate * 1e-3f << endl;\n",
        "\n",
        "    cout << \"Memory Bus Width: \" << deviceProp.memoryBusWidth << endl;\n",
        "\n",
        "    if (deviceProp.l2CacheSize){\n",
        "        cout << \"L2 Cache size: \" << deviceProp.l2CacheSize << endl;\n",
        "    }\n",
        "\n",
        "    cout << \" Max Texture 1D \" << deviceProp.maxTexture1D << endl;\n",
        "    cout << \" Max Texture 2D[0] \" << deviceProp.maxTexture2D[0] << endl;\n",
        "    cout << \" Max Texture 2D[1] \" << deviceProp.maxTexture2D[0] << endl;\n",
        "    cout << \" Max Texture 3D[0] \" << deviceProp.maxTexture3D[0] << endl;\n",
        "    cout << \" Max Texture 3D[1] \" << deviceProp.maxTexture3D[1] << endl;\n",
        "    cout << \" Max Texture 3D[2] \" << deviceProp.maxTexture3D[2] << endl;\n",
        "\n",
        "    cout << \"Total const memory: \" << deviceProp.totalConstMem << endl;\n",
        "    cout << \"Shared memory per Block: \" << deviceProp.sharedMemPerBlock << endl;\n",
        "    cout << \"Register per Block: \" << deviceProp.regsPerBlock << endl;\n",
        "\n",
        "    cout << \"Warp Size: \" << deviceProp.warpSize << endl;\n",
        "\n",
        "    cout << \"Max Threads per SM: \" << deviceProp.maxThreadsPerMultiProcessor << endl;\n",
        "\n",
        "    cout << \"Max Threads per Block: \" << deviceProp.maxThreadsPerBlock << endl;\n",
        "\n",
        "    cout << \"Max Thread DIM[0]: \" << deviceProp.maxThreadsDim[0] << endl;\n",
        "    cout << \"Max Thread DIM[1]: \" << deviceProp.maxThreadsDim[1] << endl;\n",
        "    cout << \"Max Thread DIM[2]: \" << deviceProp.maxThreadsDim[2] << endl;\n",
        "\n",
        "    cout << \"Max Grid Size[0]: \" << deviceProp.maxGridSize[0] << endl;\n",
        "    cout << \"Max Grid Size[1]: \" << deviceProp.maxGridSize[1] << endl;\n",
        "    cout << \"Max Grid Size[2]: \" << deviceProp.maxGridSize[2] << endl;\n",
        "\n",
        "    cout << \"Max mem pitch: \" << deviceProp.memPitch << endl;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVmmJZKgDXwE",
        "outputId": "ea5ffd78-53e2-4e9b-f8b3-e873ecfe7d44"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting deviceInfo.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc deviceInfo.cu -o deviceInfo"
      ],
      "metadata": {
        "id": "-AjXpP4r_J6a"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./deviceInfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "008ENFKD_J4D",
        "outputId": "ea674231-394a-4131-c04b-da11771237d9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected device-1 CUDA compatible device\n",
            "Device no: 0 and Device Name: Tesla T4Cuda Driver Version 12.2\n",
            "Runtime Version 12.2\n",
            "Cuda Capability: Major version 7 Minor Version: 5\n",
            "Total Amount of Global Memory: 14.7481 MBytes\n",
            "Max Multi-processor: 40\n",
            "GPU Clock Rate: 1590\n",
            "Memory Clock Rate: 5001\n",
            "Memory Bus Width: 256\n",
            "L2 Cache size: 4194304\n",
            " Max Texture 1D 131072\n",
            " Max Texture 2D[0] 131072\n",
            " Max Texture 2D[1] 131072\n",
            " Max Texture 3D[0] 16384\n",
            " Max Texture 3D[1] 16384\n",
            " Max Texture 3D[2] 16384\n",
            "Total const memory: 65536\n",
            "Shared memory per Block: 49152\n",
            "Register per Block: 65536\n",
            "Warp Size: 32\n",
            "Max Threads per SM: 1024\n",
            "Max Threads per Block: 1024\n",
            "Max Thread DIM[0]: 1024\n",
            "Max Thread DIM[1]: 1024\n",
            "Max Thread DIM[2]: 64\n",
            "Max Grid Size[0]: 2147483647\n",
            "Max Grid Size[1]: 65535\n",
            "Max Grid Size[2]: 65535\n",
            "Max mem pitch: 2147483647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -q -i 0 -d MEMORY"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5fkKYR5BTkM",
        "outputId": "acdab919-e2c8-4eca-c3cc-e6f566199eb8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============NVSMI LOG==============\n",
            "\n",
            "Timestamp                                 : Thu May 23 10:38:53 2024\n",
            "Driver Version                            : 535.104.05\n",
            "CUDA Version                              : 12.2\n",
            "\n",
            "Attached GPUs                             : 1\n",
            "GPU 00000000:00:04.0\n",
            "    FB Memory Usage\n",
            "        Total                             : 15360 MiB\n",
            "        Reserved                          : 257 MiB\n",
            "        Used                              : 0 MiB\n",
            "        Free                              : 15101 MiB\n",
            "    BAR1 Memory Usage\n",
            "        Total                             : 256 MiB\n",
            "        Used                              : 2 MiB\n",
            "        Free                              : 254 MiB\n",
            "    Conf Compute Protected Memory Usage\n",
            "        Total                             : 0 MiB\n",
            "        Used                              : 0 MiB\n",
            "        Free                              : 0 MiB\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -q -i 0 -d UTILIZATION"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6H4Q0xAbBTeC",
        "outputId": "cfc7bc88-e00f-47c8-9eb2-7760cea9f0c7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============NVSMI LOG==============\n",
            "\n",
            "Timestamp                                 : Thu May 23 10:39:24 2024\n",
            "Driver Version                            : 535.104.05\n",
            "CUDA Version                              : 12.2\n",
            "\n",
            "Attached GPUs                             : 1\n",
            "GPU 00000000:00:04.0\n",
            "    Utilization\n",
            "        Gpu                               : 0 %\n",
            "        Memory                            : 0 %\n",
            "        Encoder                           : 0 %\n",
            "        Decoder                           : 0 %\n",
            "        JPEG                              : 0 %\n",
            "        OFA                               : 0 %\n",
            "    GPU Utilization Samples\n",
            "        Duration                          : 14.02 sec\n",
            "        Number of Samples                 : 71\n",
            "        Max                               : 0 %\n",
            "        Min                               : 0 %\n",
            "        Avg                               : 0 %\n",
            "    Memory Utilization Samples\n",
            "        Duration                          : 14.02 sec\n",
            "        Number of Samples                 : 71\n",
            "        Max                               : 0 %\n",
            "        Min                               : 0 %\n",
            "        Avg                               : 0 %\n",
            "    ENC Utilization Samples\n",
            "        Duration                          : 14.02 sec\n",
            "        Number of Samples                 : 71\n",
            "        Max                               : 0 %\n",
            "        Min                               : 0 %\n",
            "        Avg                               : 0 %\n",
            "    DEC Utilization Samples\n",
            "        Duration                          : 14.02 sec\n",
            "        Number of Samples                 : 71\n",
            "        Max                               : 0 %\n",
            "        Min                               : 0 %\n",
            "        Avg                               : 0 %\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -q -i 0 -d CLOCK"
      ],
      "metadata": {
        "id": "mlXvTog5BTac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -q -i 0 -d COMPUTE"
      ],
      "metadata": {
        "id": "k5mHL_CkCTFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -q -i 0 -d PERFORMANCE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkgxRepNCTDY",
        "outputId": "ba575319-3db6-4ce9-c136-791ea5e6fb7c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============NVSMI LOG==============\n",
            "\n",
            "Timestamp                                 : Thu May 23 10:40:27 2024\n",
            "Driver Version                            : 535.104.05\n",
            "CUDA Version                              : 12.2\n",
            "\n",
            "Attached GPUs                             : 1\n",
            "GPU 00000000:00:04.0\n",
            "    Performance State                     : P8\n",
            "    Clocks Event Reasons\n",
            "        Idle                              : Active\n",
            "        Applications Clocks Setting       : Not Active\n",
            "        SW Power Cap                      : Not Active\n",
            "        HW Slowdown                       : Not Active\n",
            "            HW Thermal Slowdown           : Not Active\n",
            "            HW Power Brake Slowdown       : Not Active\n",
            "        Sync Boost                        : Not Active\n",
            "        SW Thermal Slowdown               : Not Active\n",
            "        Display Clock Setting             : Not Active\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile sumArraysGPU2d.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "#include <sys/time.h>\n",
        "\n",
        "using namespace std;\n",
        "// used for checking the errors in the function calls and print them\n",
        "#define CHECK(call)                                                                 \\\n",
        "{                                                                                   \\\n",
        "    const cudaError_t error = call;                                                 \\\n",
        "    if (error != cudaSuccess)                                                       \\\n",
        "    {                                                                               \\\n",
        "        cout << \"code: \" << error << \"reason: \" << cudaGetErrorString(error) << endl;\\\n",
        "        exit(1);                                                                    \\\n",
        "    }                                                                               \\\n",
        "}\n",
        "// Comparing the result of matrix operation by host function and kernel\n",
        "void checkResult(float *hostRef, float *gpuRef, const int N){\n",
        "    double epsilon = 1.0E-8;\n",
        "    bool match = 1;\n",
        "    for (int i = 0; i < N; i++){\n",
        "        if(abs(hostRef[i] - gpuRef[i]) > epsilon){\n",
        "            match = 0;\n",
        "            cout << \"Arrays do not match.\" << endl;\n",
        "            cout << \"host: \" << hostRef[i] << \"gpu: \" << gpuRef[i] << endl;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "    if (match) cout << \"Arrays Match\" << endl;\n",
        "}\n",
        "\n",
        "// summing array on host\n",
        "void sumArrayOnHost(float *a, float *b, float *c, const int N){\n",
        "    // enumerate and sum\n",
        "    for(int idx = 0; idx < N; idx++){\n",
        "        c[idx] = a[idx] + b[idx]; // just take two elements and add them\n",
        "    }\n",
        "}\n",
        "\n",
        "void initialData(float *ip, int size){\n",
        "    // time_t t;  // t is of time time_t, and its address is sent to srand\n",
        "    // srand((unsigned int) time(&t)); // the returned time_t value is casted\n",
        "    srand(static_cast<unsigned int>(time(0)));\n",
        "    for (int j=0; j < size; j++){\n",
        "        ip[j] = (float) ( rand() & 0xFF ) / 10.0f;\n",
        "    }\n",
        "}\n",
        "\n",
        "double cpuSecond(){\n",
        "    struct timeval tp;\n",
        "    gettimeofday(&tp, NULL);\n",
        "    return (double)tp.tv_sec + (double)tp.tv_usec * 1.e-6;\n",
        "}\n",
        "\n",
        "__global__ void sumArrayOnGPU2d(float *A, float *B, float *C, int nx, int ny){\n",
        "    unsigned int ix = threadIdx.x + blockIdx.x * blockDim.x; // calc ix from the ids of threads & blocks\n",
        "    unsigned int iy = threadIdx.y + blockIdx.y * blockDim.y; // calc iy from the ids of blocks & threads\n",
        "    unsigned int idx = iy * nx + ix;  // calc the id of the array from ix & iy\n",
        "    if(ix < nx && iy < ny){\n",
        "        C[idx] = A[idx] + B[idx];  // the 2d matrix is linearly placed in the memory\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void sumArrayOnGPU1d(float *A, float *B, float *C, int nx, int ny){\n",
        "    unsigned int ix = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    // calc ix from the ids of threads & blocks\n",
        "    if(ix < nx){\n",
        "        // for every spawned thread, below loop executes for ny times\n",
        "        for (int iy = 0; iy < ny; iy++){\n",
        "            int idx = iy * nx + ix;\n",
        "            // this is inside the loop now.\n",
        "            C[idx] = A[idx] + B[idx];\n",
        "            // the 2d matrix is linearly placed in the memory\n",
        "        }\n",
        "    }\n",
        "}\n",
        "// block(32, 1) and grid((nx + block.x - 1) / block.x, 1)\n",
        "\n",
        "__global__ void sumArrayOnGPUmix(float *A, float *B, float *C, int nx, int ny)\n",
        "{\n",
        "    unsigned int ix = threadIdx.x + blockIdx.x * blockDim.x; // calc ix from the ids of threads & blocks\n",
        "    unsigned int iy = blockIdx.y;\n",
        "    unsigned int idx = iy * nx + ix;\n",
        "    if(ix < nx && iy < ny) C[idx] = A[idx] + B[idx];  // the blocks are growing along cols, sideways\n",
        "} // block(32, 1) and grid((nx + block.x - 1) / block.x, 1)\n",
        "\n",
        "\n",
        "int main(){\n",
        "    int dev = 0; // setup device to be 0\n",
        "    cudaSetDevice(dev);\n",
        "\n",
        "    int nx = 1 << 14; // set data 16,384 elems\n",
        "    int ny = 1 << 14; // set data 16,384 elems\n",
        "    cout << \"Vector x size: \" << nx << endl;\n",
        "    cout << \"Vector y size: \" << ny << endl;\n",
        "\n",
        "    int nxy = nx * ny;\n",
        "    size_t nBytes = nxy * sizeof(float);\n",
        "\n",
        "    float *h_A, *h_B, *hostRef, *gpuRef;\n",
        "    // https://www.geeksforgeeks.org/malloc-vs-new/\n",
        "    // we can implement new based memory allocation\n",
        "    h_A = (float *)malloc(nBytes);  // its going to linear memory alloc\n",
        "    h_B = (float *)malloc(nBytes);\n",
        "\n",
        "    hostRef = (float *)malloc(nBytes);\n",
        "    gpuRef = (float *)malloc(nBytes);\n",
        "\n",
        "    initialData(h_A, nxy);\n",
        "    initialData(h_B, nxy);\n",
        "\n",
        "    memset(hostRef, 0, nBytes);\n",
        "    memset(gpuRef, 0, nBytes);\n",
        "\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc((float **)&d_A , nBytes);\n",
        "    // &d_A is address in device memory, which is holding the\n",
        "    // pointer to the array of data\n",
        "    cudaMalloc((float **)&d_B , nBytes);\n",
        "    cudaMalloc((float **)&d_C , nBytes);\n",
        "\n",
        "    // move data from host to device\n",
        "    cudaMemcpy(d_A, h_A, nBytes, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, nBytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "    int dimx = 32; // 32, 16\n",
        "    int dimy = 32; // 16, 16\n",
        "    // invoke kernel at host side\n",
        "    dim3 block (dimx, dimy);\n",
        "    dim3 grid ((nx + block.x - 1) / block.x, (ny + block.y -1) / block.y);\n",
        "    double iSt = cpuSecond();\n",
        "    sumArrayOnGPU1d<<<grid, block>>>(d_A, d_B, d_C, nx, ny);\n",
        "    double iEl = cpuSecond() - iSt;\n",
        "\n",
        "    cout << \"grid.x \" << grid.x << \"block.x \" << block.x << endl;\n",
        "    printf(\"sumArrayOnGPU1D<<<(%d, %d), (%d, %d)>>> elapsed %f sec. \\n\",\n",
        "          grid.x, grid.y, block.x, block.y, iEl);\n",
        "\n",
        "    iSt = cpuSecond();\n",
        "    sumArrayOnGPU2d<<<grid, block>>>(d_A, d_B, d_C, nx, ny);\n",
        "    iEl = cpuSecond() - iSt;\n",
        "\n",
        "    cout << \"grid.x \" << grid.x << \"block.x \" << block.x << endl;\n",
        "    printf(\"sumArrayOnGPU2d<<<(%d, %d), (%d, %d)>>> elapsed %f sec. \\n\",\n",
        "          grid.x, grid.y, block.x, block.y, iEl);\n",
        "\n",
        "    cudaMemcpy(gpuRef, d_C, nBytes, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    sumArrayOnHost(h_A, h_B, hostRef, nxy);\n",
        "\n",
        "    checkResult(hostRef, gpuRef, nxy);\n",
        "\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(hostRef);\n",
        "    free(gpuRef);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3K1T-9zjCS_9",
        "outputId": "1b2c61ee-d378-4891-9f01-ed03e2d7828a"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting sumArraysGPU2d.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc sumArraysGPU2d.cu -o sumArraysGPU2d"
      ],
      "metadata": {
        "id": "_SkATRLoDkPc"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./sumArraysGPU2d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWeFBIHcDkNK",
        "outputId": "03d9a506-8c92-4a37-989f-3bbe61e6975a"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector x size: 16384\n",
            "Vector y size: 16384\n",
            "grid.x 512block.x 32\n",
            "sumArrayOnGPU1D<<<(512, 512), (32, 32)>>> elapsed 0.000311 sec. \n",
            "grid.x 512block.x 32\n",
            "sumArrayOnGPU2d<<<(512, 512), (32, 32)>>> elapsed 0.000025 sec. \n",
            "Arrays Match\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fr-1xbH-DkKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eGzasvXbDkIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2hEzE_G1DkFE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}