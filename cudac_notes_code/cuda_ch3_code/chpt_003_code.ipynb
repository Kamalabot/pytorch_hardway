{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting simpleDivergence.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile simpleDivergence.cu\n",
    "#include <iostream>\n",
    "#include <sys/time.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "inline double seconds()\n",
    "{\n",
    "    struct timeval tp;\n",
    "    struct timezone tzp;\n",
    "    int i = gettimeofday(&tp, &tzp);\n",
    "    return ((double)tp.tv_sec + (double)tp.tv_usec * 1.e-6);\n",
    "}\n",
    "\n",
    "__global__ void mathKernel1(float *c)\n",
    "{\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    float ia, ib;\n",
    "    ia = ib = 0.0f;\n",
    "    // following creates a warp divergence\n",
    "    if (tid % 2 == 0){\n",
    "        ia = 100.0f;\n",
    "    }\n",
    "    else\n",
    "    {\n",
    "        ib = 200.0f;\n",
    "    }\n",
    "    c[tid] = ia + ib;\n",
    "}\n",
    "\n",
    "__global__ void mathKernel2(float *c){\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    float ia, ib;\n",
    "    ia = ib = 0.0f;\n",
    "    \n",
    "    if((tid / warpSize) % 2 == 0)\n",
    "    {\n",
    "        ia = 100.0f;\n",
    "    }\n",
    "    else\n",
    "    {\n",
    "        ib = 200.0f;\n",
    "    }\n",
    "    c[tid] = ia + ib;\n",
    "}\n",
    "\n",
    "__global__ void warmingUp(float *c){\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    float ia, ib;\n",
    "    ia = ib = 0.0f;\n",
    "    \n",
    "    if((tid / warpSize) % 2 == 0)\n",
    "    {\n",
    "        ia = 100.0f;\n",
    "    }\n",
    "    else\n",
    "    {\n",
    "        ib = 200.0f;\n",
    "    }\n",
    "    c[tid] = ia + ib;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int dev = 0;\n",
    "    cudaDeviceProp deviceProp;\n",
    "    CHECK(cudaGetDeviceProperties(&deviceProp, dev));\n",
    "    cout << \"Using Device: \" << deviceProp.name;\n",
    "\n",
    "    int size = 64;\n",
    "    int blocksize = 64;\n",
    "\n",
    "    cout << \"Data Size: \" << size;\n",
    "\n",
    "    dim3 block(blocksize, 1);\n",
    "    dim3 grid((size + block.x - 1) / block.x, 1);\n",
    "\n",
    "    cout << \"Threads: \" << block.x << \"Blocks: \" << grid.x << endl;\n",
    "\n",
    "    float *d_C;\n",
    "\n",
    "    size_t nBytes = size * sizeof(float);\n",
    "    cudaMalloc((float **)&d_C, nBytes);    \n",
    "\n",
    "    size_t iSt, iEl;\n",
    "\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    iSt = seconds(); \n",
    "    warmingUp<<<grid, block>>>(d_C);\n",
    "\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    iEl = seconds() - iSt;\n",
    "\n",
    "    iSt = seconds(); \n",
    "    mathKernel1<<<grid, block>>>(d_C);\n",
    "\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    iEl = seconds() - iSt;\n",
    "\n",
    "    cout << \"MathKernel1<<<\" << grid.x << \", \" << block.x << \">>>\" << \"time elapsed \" << iEl << endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing simpleDeviceQuery.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile simpleDeviceQuery.cu\n",
    "\n",
    "#include <iostream>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "int main(){\n",
    "    int iDev = 0;\n",
    "    cudaDeviceProp iProp;\n",
    "    cudaGetDeviceProperties(&iProp, iDev);\n",
    "\n",
    "    cout << \"Device name: \" << iProp.name << endl;\n",
    "\n",
    "    cout << \"Number of multi-processor: \" << iProp.multiProcessorCount << endl;\n",
    "    \n",
    "    cout << \"Constant Memory: \" << iProp.totalConstMem / 1024.0 << endl;\n",
    "    cout << \"Number of registers per block:  \" << iProp.regsPerBlock << endl;\n",
    "    cout << \"Warp Size: \" << iProp.warpSize << endl;\n",
    "    cout << \"Max number of threads per block: \" << iProp.maxThreadsPerBlock << endl;\n",
    "    cout << \"Threads per multiprocessor: \" << iProp.maxThreadsPerMultiProcessor << endl;\n",
    "    cout << \"Warps per multiprocessor: \" << iProp.maxThreadsPerMultiProcessor / 32 << endl;\n",
    "    return EXIT_SUCCESS;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sumArraysGPU2dCLI.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile sumArraysGPU2dCLI.cu\n",
    "#include <iostream>\n",
    "#include <cuda_runtime.h>\n",
    "#include <sys/time.h>\n",
    "\n",
    "using namespace std;\n",
    "// used for checking the errors in the function calls and print them\n",
    "\n",
    "#define CHECK(call)                                                                 \\\n",
    "{                                                                                   \\\n",
    "    const cudaError_t error = call;                                                 \\\n",
    "    if (error != cudaSuccess)                                                       \\\n",
    "    {                                                                               \\\n",
    "        cout << \"code: \" << error << \"reason: \" << cudaGetErrorString(error) << endl;\\\n",
    "        exit(1);                                                                    \\\n",
    "    }                                                                               \\\n",
    "}\n",
    "\n",
    "// Comparing the result of matrix operation by host function and kernel\n",
    "void checkResult(float *hostRef, float *gpuRef, const int N){\n",
    "    double epsilon = 1.0E-8;\n",
    "    bool match = 1;\n",
    "    for (int i = 0; i < N; i++){\n",
    "        if(abs(hostRef[i] - gpuRef[i]) > epsilon){\n",
    "            match = 0;\n",
    "            cout << \"Arrays do not match.\" << endl;\n",
    "            cout << \"host: \" << hostRef[i] << \"gpu: \" << gpuRef[i] << endl;\n",
    "            break;\n",
    "        }\n",
    "    }\n",
    "    if (match) cout << \"Arrays Match\" << endl;\n",
    "}\n",
    "\n",
    "void initialData(float *ip, int size){\n",
    "    time_t t;  // t is of time time_t, and its address is sent to srand\n",
    "    // srand((unsigned int) time(&t)); // the returned time_t value is casted\n",
    "    srand(static_cast<unsigned int>(time(0)));\n",
    "    for (int j=0; j < size; j++){\n",
    "        ip[j] = (float) ( rand() & 0xFF ) / 10.0f;\n",
    "    }\n",
    "}\n",
    "\n",
    "int cpuSecond(){\n",
    "    struct timeval tp;\n",
    "    gettimeofday(&tp, NULL);\n",
    "    return (double)tp.tv_sec + (double)tp.tv_usec * 1.e-6;\n",
    "}\n",
    "\n",
    "__global__ void sumArrayOnGPU2d(float *A, float *B, float *C, int nx, int ny){\n",
    "    unsigned int ix = threadIdx.x + blockIdx.x * blockDim.x; // calc ix from the ids of threads & blocks\n",
    "    unsigned int iy = threadIdx.y + blockIdx.y * blockDim.y; // calc iy from the ids of blocks & threads\n",
    "    unsigned int idx = iy * nx + ix;  // calc the id of the array from ix & iy\n",
    "    if(ix < nx && iy < ny){\n",
    "        C[idx] = A[idx] + B[idx];  // the 2d matrix is linearly placed in the memory\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(int argc, char* argv[]){\n",
    "    int dev = 0; // setup device to be 0\n",
    "    cudaSetDevice(dev);\n",
    "\n",
    "    int nx = 1 << 14; // set data 16,384 elems\n",
    "    int ny = 1 << 14; // set data 16,384 elems\n",
    "    cout << \"Vector x size: \" << nx << endl;\n",
    "    cout << \"Vector y size: \" << ny << endl;\n",
    "    \n",
    "    int nxy = nx * ny;\n",
    "    size_t nBytes = nxy * sizeof(float); \n",
    "\n",
    "    float *h_A, *h_B, *hostRef, *gpuRef;\n",
    "    // https://www.geeksforgeeks.org/malloc-vs-new/ \n",
    "    // we can implement new based memory allocation \n",
    "    h_A = (float *)malloc(nBytes);  // its going to linear memory alloc\n",
    "    h_B = (float *)malloc(nBytes);\n",
    "\n",
    "    hostRef = (float *)malloc(nBytes);\n",
    "    gpuRef = (float *)malloc(nBytes);\n",
    "\n",
    "    initialData(h_A, nxy);\n",
    "    initialData(h_B, nxy);\n",
    "\n",
    "    memset(hostRef, 0, nBytes);\n",
    "    memset(gpuRef, 0, nBytes);\n",
    "\n",
    "    float *d_A, *d_B, *d_C;\n",
    "    cudaMalloc((float **)&d_A , nBytes);\n",
    "    // &d_A is address in device memory, which is holding the \n",
    "    // pointer to the array of data\n",
    "    cudaMalloc((float **)&d_B , nBytes);\n",
    "    cudaMalloc((float **)&d_C , nBytes);\n",
    "\n",
    "    // move data from host to device\n",
    "    cudaMemcpy(d_A, h_A, nBytes, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_B, h_B, nBytes, cudaMemcpyHostToDevice);\n",
    "\n",
    "    // int dimx = 32; // 32, 16\n",
    "    // int dimy = 32; // 16, 16\n",
    "    // invoke kernel at host side\n",
    "    if (argc > 2) {\n",
    "        dimx = atoi(arvg[1]);\n",
    "        dimy = atoi(arvg[2]);\n",
    "    }\n",
    "    dim3 block (dimx, dimy);\n",
    "    dim3 grid ((nx + block.x - 1) / block.x, (ny + block.y -1) / block.y);\n",
    "\n",
    "    double iSt = cpuSecond();    \n",
    "    sumArrayOnGPU2d<<<grid, block>>>(d_A, d_B, d_C, nx, ny);\n",
    "    double iEl = cpuSecond() - iSt;\n",
    "\n",
    "    cout << \"grid.x \" << grid.x << \"block.x \" << block.x << endl;\n",
    "    printf(\"sumArrayOnGPU2d<<<(%d, %d), (%d, %d)>>> elapsed %f sec. \\n\",\n",
    "          grid.x, grid.y, block.x, block.y, iEl);\n",
    "\n",
    "    cudaMemcpy(gpuRef, d_C, nBytes, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    sumArrayOnHost(h_A, h_B, hostRef, nxy);\n",
    "\n",
    "    checkResult(hostRef, gpuRef, nxy);\n",
    "\n",
    "    cudaFree(d_A);\n",
    "    cudaFree(d_B);\n",
    "    cudaFree(d_C);\n",
    "\n",
    "    free(h_A);\n",
    "    free(h_B);\n",
    "    free(hostRef);\n",
    "    free(gpuRef);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
