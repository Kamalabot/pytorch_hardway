{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook deals with all things Binary Classification. Starting with basic NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F \n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7763, -0.0984, -1.1924,  1.6989]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = torch.randn((1, 4))\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8688)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig = nn.Sigmoid()  # the function exists between 0 to 1 like probability, so we use it\n",
    "sig(n).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a simple NN model\n",
    "\n",
    "class BinClassify(nn.Module):\n",
    "    def __init__(self, in_features, out_features, hidden_features):\n",
    "        super(BinClassify, self).__init__()\n",
    "        self.lin1 = nn.Linear(in_features, hidden_features)  # first layer connected to hidden\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lin2 = nn.Linear(hidden_features, out_features)  # hidden to out features\n",
    "        self.sig = nn.Sigmoid()  # \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        # print(x)\n",
    "        x = self.relu(x)\n",
    "        # print(x)\n",
    "        x = self.lin2(x)\n",
    "        # print(x)\n",
    "        return self.sig(x)\n",
    "    \n",
    "bingklassify = BinClassify(4, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "x, y = datasets.make_classification(n_features=4,n_classes=2, n_informative=2, \n",
    "                                n_samples=100,)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "\n",
    "class Bingset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = torch.from_numpy(x.astype(np.float32))\n",
    "        self.y = torch.from_numpy(y.astype(np.float32))\n",
    "        self.y = self.y.reshape(-1, 1)\n",
    "        self.samples = self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.1921, -1.1006, -0.6595,  0.6403]), tensor([0.]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clas_set = Bingset(x=x, y=y)\n",
    "clas_set[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.1027,  1.9780,  0.4469, -1.7661],\n",
       "         [-1.1921, -1.1006, -0.6595,  0.6403],\n",
       "         [ 0.0146, -0.3675, -0.0845,  0.3269]]),\n",
       " tensor([[1.],\n",
       "         [0.],\n",
       "         [0.]])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clas_loader = DataLoader(clas_set, 3)\n",
    "iter_clas = iter(clas_loader)\n",
    "next(iter_clas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5770],\n",
       "        [0.5532],\n",
       "        [0.5460]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bingklassify(next(iter_clas)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred is:  tensor([[0.5465],\n",
      "        [0.6297],\n",
      "        [0.6270]], grad_fn=<SigmoidBackward0>)\n",
      "Actual is: tensor([[1.],\n",
      "        [0.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "pred = bingklassify(next(iter_clas)[0])\n",
    "print(\"Pred is: \", pred)\n",
    "print(\"Actual is:\", next(iter_clas)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0., grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn = nn.CrossEntropyLoss()\n",
    "pred = bingklassify(next(iter_clas)[0])\n",
    "loss = fn(pred, next(iter_clas)[1])\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6484, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn = nn.BCELoss()\n",
    "pred = bingklassify(next(iter_clas)[0])\n",
    "loss = fn(pred, next(iter_clas)[1])\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss()\n",
    "fn = nn.BCELoss()  # Binary Cross entropy had to be used.\n",
    "optimiser = optim.Adam(params=bingklassify.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is 0 and loss is: 0.53\n",
      "Epoch is 5 and loss is: 0.05\n",
      "Epoch is 10 and loss is: 0.03\n",
      "Epoch is 15 and loss is: 0.02\n",
      "Epoch is 20 and loss is: 0.01\n",
      "Epoch is 25 and loss is: 0.00\n",
      "Epoch is 30 and loss is: 0.00\n",
      "Epoch is 35 and loss is: 0.00\n",
      "Epoch is 40 and loss is: 0.00\n",
      "Epoch is 45 and loss is: 0.00\n",
      "Epoch is 50 and loss is: 0.00\n",
      "Epoch is 55 and loss is: 0.00\n",
      "Epoch is 60 and loss is: 0.00\n",
      "Epoch is 65 and loss is: 0.00\n",
      "Epoch is 70 and loss is: 0.00\n",
      "Epoch is 75 and loss is: 0.00\n",
      "Epoch is 80 and loss is: 0.00\n",
      "Epoch is 85 and loss is: 0.00\n",
      "Epoch is 90 and loss is: 0.00\n",
      "Epoch is 95 and loss is: 0.00\n"
     ]
    }
   ],
   "source": [
    "# 100 pass through the full data using dataloader\n",
    "for ep in range(100):\n",
    "    for ind, batch in enumerate(clas_loader):\n",
    "        # print(batch[0].shape)  # torch.size([3, 4])\n",
    "        pred_batch  = bingklassify(batch[0])\n",
    "        loss_cr = fn(pred_batch, batch[1])\n",
    "        # print(loss_cr.item())\n",
    "        loss_cr.backward()  # backward pass happens with ease, even though there are multiple elements\n",
    "        optimiser.step()\n",
    "        optimiser.zero_grad()\n",
    "    if ep % 5 == 0:\n",
    "        print(f\"Epoch is {ep} and loss is: {loss_cr.item():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0012])\n",
      "compared to:  tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_pred = bingklassify(clas_set[10][0])\n",
    "    print(test_pred)\n",
    "    print(\"compared to: \", clas_set[10][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 pass through full data using regular tensor\n",
    "for ep in range(150):\n",
    "    pred = regmodel(rand_x)\n",
    "    # print('pred', pred)\n",
    "    lo = criterion(pred, rand_y)\n",
    "    # print(lo)\n",
    "    lo.backward()\n",
    "    optimiser.step()\n",
    "    optimiser.zero_grad()\n",
    "    if ep % 5 == 0:\n",
    "        print(f\"Epoch is {ep} and loss is {lo.item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.2124]) tensor([-5.3929])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    pred = regmodel(rand_x[0])\n",
    "    print(pred, rand_y[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
