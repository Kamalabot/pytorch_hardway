{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook contains myriad of pytorch methods, that are used in LLama model building. The same is collected here for reference\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nn.Parameter, used in RMSNorm class\n",
    "dim = 10\n",
    "\n",
    "param = nn.Parameter(torch.ones(10))  # will become part of the Module parameter\n",
    "\n",
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5778, 0.2681, 0.1957, 0.2452, 0.0567, 0.5619, 0.1121, 0.6420, 0.7265,\n",
      "         0.2651]])\n",
      "tensor([[1.3156, 1.9312, 2.2606, 2.0193, 4.1983, 1.3341, 2.9868, 1.2480, 1.1733,\n",
      "         1.9420]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(size=(1, 10))\n",
    "print(x)\n",
    "rsqrt = torch.rsqrt(x)  # Returns a new tensor with the reciprocal of the square-root of each elements \n",
    "print(rsqrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.],\n",
       "        [ 2.,  4.,  6.],\n",
       "        [ 3.,  6.,  9.],\n",
       "        [ 4.,  8., 12.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = torch.arange(1., 5.) # tensor([1., 2., 3., 4.])\n",
    "v2 = torch.arange(1., 4.) # tensor([1., 2., 3.])\n",
    "torch.outer(v1, v2)  # Outer product of :attr:`input` and :attr:`vec2`\n",
    "# where each element is the product of elements from the input tensors at corresponding indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.],\n",
       "        [ 2.,  4.,  6.],\n",
       "        [ 3.,  6.,  9.],\n",
       "        [ 4.,  8., 12.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.inner(v1.reshape(-1, 1), v2.reshape(-1, 1))\n",
    "#  summing the element-wise product of corresponding elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(30.)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2 = torch.arange(1., 5.)\n",
    "torch.inner(v1, v2)\n",
    "#  summing the element-wise product of corresponding elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.5403+0.8415j, -0.8323+1.8186j, -2.9700+0.4234j, -2.6146-3.0272j])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v3 = torch.polar(v1, v2)  # compute complex numbers in the polar form c = R * exp(m * theta)\n",
    "v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.3389-0.4209j,  0.0241-0.2106j,  0.9575+0.3471j,  1.4991+0.4845j])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.randn(4, 2)\n",
    "x_comp = torch.view_as_complex(x)\n",
    "x_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3389, -0.4209],\n",
       "        [ 0.0241, -0.2106],\n",
       "        [ 0.9575,  0.3471],\n",
       "        [ 1.4991,  0.4845]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_real = torch.view_as_real(x_comp)\n",
    "x_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_x = x.expand(4, 4, 2) #  Returns a new view of the :attr:`self` tensor with singleton dimensions expanded to a larger size.\n",
    "exp_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A singleton dimension is a dimension in a tensor with size 1. In other words, it is a dimension that has only one element along that axis. Singleton dimensions are often introduced for broadcasting purposes, allowing operations between tensors with different shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3389, -0.4209],\n",
       "         [ 0.0241, -0.2106],\n",
       "         [ 0.9575,  0.3471],\n",
       "         [ 1.4991,  0.4845]],\n",
       "\n",
       "        [[-1.3389, -0.4209],\n",
       "         [ 0.0241, -0.2106],\n",
       "         [ 0.9575,  0.3471],\n",
       "         [ 1.4991,  0.4845]],\n",
       "\n",
       "        [[-1.3389, -0.4209],\n",
       "         [ 0.0241, -0.2106],\n",
       "         [ 0.9575,  0.3471],\n",
       "         [ 1.4991,  0.4845]],\n",
       "\n",
       "        [[-1.3389, -0.4209],\n",
       "         [ 0.0241, -0.2106],\n",
       "         [ 0.9575,  0.3471],\n",
       "         [ 1.4991,  0.4845]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x.contiguous() # Returns a contiguous in memory tensor containing the same data a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.1416, 3.1416, 3.1416],\n",
       "        [3.1416, 3.1416, 3.1416]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.full((2, 3), 3.141592)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
