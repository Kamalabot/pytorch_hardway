{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-05-18T02:14:42.794015Z","iopub.status.busy":"2024-05-18T02:14:42.793158Z","iopub.status.idle":"2024-05-18T02:15:11.952889Z","shell.execute_reply":"2024-05-18T02:15:11.951791Z","shell.execute_reply.started":"2024-05-18T02:14:42.793973Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["!pip install ninja\n","!sudo apt update\n","!sudo apt install ccache -y\n","#!sudo apt install g++-11 -y"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-05-18T02:23:32.789377Z","iopub.status.busy":"2024-05-18T02:23:32.788535Z","iopub.status.idle":"2024-05-18T02:27:24.787811Z","shell.execute_reply":"2024-05-18T02:27:24.786537Z","shell.execute_reply.started":"2024-05-18T02:23:32.789332Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["!sudo apt update -y && sudo apt upgrade -y"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T02:27:37.329264Z","iopub.status.busy":"2024-05-18T02:27:37.328830Z","iopub.status.idle":"2024-05-18T02:27:40.005904Z","shell.execute_reply":"2024-05-18T02:27:40.004772Z","shell.execute_reply.started":"2024-05-18T02:27:37.329223Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","\u001b[1;31mE: \u001b[0mUnable to locate package g++-11\u001b[0m\n"]}],"source":["!sudo apt install g++-11 -y"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T02:27:47.194396Z","iopub.status.busy":"2024-05-18T02:27:47.193441Z","iopub.status.idle":"2024-05-18T02:27:48.206681Z","shell.execute_reply":"2024-05-18T02:27:48.205541Z","shell.execute_reply.started":"2024-05-18T02:27:47.194352Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n","Copyright (C) 2019 Free Software Foundation, Inc.\n","This is free software; see the source for copying conditions.  There is NO\n","warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n","\n"]}],"source":["!gcc --version"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T02:22:53.554958Z","iopub.status.busy":"2024-05-18T02:22:53.554128Z","iopub.status.idle":"2024-05-18T02:22:54.504706Z","shell.execute_reply":"2024-05-18T02:22:54.503485Z","shell.execute_reply.started":"2024-05-18T02:22:53.554918Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["c++\t c99-gcc  g++\t gcc\tx86_64-linux-gnu-g++\tx86_64-linux-gnu-gcc\n","c89-gcc  cc\t  g++-9  gcc-9\tx86_64-linux-gnu-g++-9\tx86_64-linux-gnu-gcc-9\n"]}],"source":["!ls /usr/lib/ccache"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T02:21:24.323992Z","iopub.status.busy":"2024-05-18T02:21:24.323621Z","iopub.status.idle":"2024-05-18T02:21:24.330359Z","shell.execute_reply":"2024-05-18T02:21:24.329255Z","shell.execute_reply.started":"2024-05-18T02:21:24.323957Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.utils.cpp_extension\n","import os\n","\n","os.environ['CXX'] = \"/usr/lib/ccache/g++-9\"\n","os.environ['CC'] = \"/usr/lib/ccache/gcc-9\""]},{"cell_type":"markdown","metadata":{},"source":["The output.data_ptr<float>() function returns a pointer to the underlying memory of a PyTorch tensor. This can be useful for accessing the tensor data directly, without having to go through the PyTorch API"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T02:29:39.349406Z","iopub.status.busy":"2024-05-18T02:29:39.348972Z","iopub.status.idle":"2024-05-18T02:29:39.356051Z","shell.execute_reply":"2024-05-18T02:29:39.355080Z","shell.execute_reply.started":"2024-05-18T02:29:39.349372Z"},"trusted":true},"outputs":[],"source":["# based on Jeremy's Lecture 3 notebook\n","cuda_begin = r'''\n","#include <torch/extension.h>\n","#include <stdio.h>\n","#include <c10/cuda/CUDAException.h>\n","\n","#define CHECK_CUDA(x) TORCH_CHECK(x.device().is_cuda(), #x \" must be a CUDA tensor\")\n","#define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x \" must be contiguous\")\n","#define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","\n","inline unsigned int cdiv(unsigned int a, unsigned int b) { return (a + b - 1) / b;}\n","'''\n","\n","cuda_src = cuda_begin + r'''\n","__global__ void rgb_to_grayscale_kernel(unsigned char* out, unsigned char* in, int n) {\n","    int i = blockIdx.x*blockDim.x + threadIdx.x;\n","    if (i >= n) return;\n","    out[i] = 0.2989f*in[i] + 0.5870f*in[i+n] + 0.1140f*in[i+2*n];  // fix with f found by Andreas...\n","}\n","\n","torch::Tensor rgb_to_grayscale_out(torch::Tensor output, const torch::Tensor& input) {\n","    //CHECK_INPUT(input);\n","    int h = input.size(1);\n","    int w = input.size(2);\n","    TORCH_CHECK((h == output.size(0)) || (w == output.size(1)) || (output.device() == input.device())\n","                || (output.scalar_type() == input.scalar_type()));\n","    int threads = 256;\n","    rgb_to_grayscale_kernel<<<cdiv(w*h,threads), threads>>>(\n","        output.data_ptr<unsigned char>(), input.data_ptr<unsigned char>(), w*h);\n","    C10_CUDA_KERNEL_LAUNCH_CHECK();\n","    return output;\n","}\n","\n","torch::Tensor rgb_to_grayscale(const torch::Tensor& input) {\n","    //CHECK_INPUT(input);\n","    int h = input.size(1);\n","    int w = input.size(2);\n","    auto output = torch::empty({h,w}, input.options());\n","    rgb_to_grayscale_out(output, input);\n","    return output;\n","}\n","'''\n","\n","cpp_src = \"\"\"\n","torch::Tensor rgb_to_grayscale(const torch::Tensor& input);\n","torch::Tensor rgb_to_grayscale_out(torch::Tensor outpuit, const torch::Tensor& input);\n","\"\"\""]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T02:30:28.354512Z","iopub.status.busy":"2024-05-18T02:30:28.353769Z","iopub.status.idle":"2024-05-18T02:31:38.296787Z","shell.execute_reply":"2024-05-18T02:31:38.295863Z","shell.execute_reply.started":"2024-05-18T02:30:28.354479Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["The input conditions for extension module test_ext have changed. Bumping to version 4 and re-building as test_ext_v4...\n","Detected CUDA files, patching ldflags\n","Emitting ninja build file ./build.ninja...\n","Building extension module test_ext_v4...\n","Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"]},{"name":"stdout","output_type":"stream","text":["[1/3] /usr/lib/ccache/g++-9 -MMD -MF main.o.d -DTORCH_EXTENSION_NAME=test_ext_v4 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1013\\\" -isystem /opt/conda/lib/python3.10/site-packages/torch/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++17 -c /kaggle/working/main.cpp -o main.o \n","[2/3] /usr/local/cuda/bin/nvcc  -ccbin /usr/lib/ccache/gcc-9 -DTORCH_EXTENSION_NAME=test_ext_v4 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1013\\\" -isystem /opt/conda/lib/python3.10/site-packages/torch/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 --compiler-options '-fPIC' --ptxas-options=-v -std=c++20 -std=c++17 -c /kaggle/working/cuda.cu -o cuda.cuda.o \n","nvcc warning : incompatible redefinition for option 'std', the last value of this option was used\n","ptxas info    : 1 bytes gmem\n","ptxas info    : Compiling entry function '_Z23rgb_to_grayscale_kernelPhS_i' for 'sm_60'\n","ptxas info    : Function properties for _Z23rgb_to_grayscale_kernelPhS_i\n","    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","ptxas info    : Used 12 registers, 340 bytes cmem[0], 8 bytes cmem[2]\n","[3/3] /usr/lib/ccache/g++-9 main.o cuda.cuda.o -shared -L/opt/conda/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o test_ext_v4.so\n"]},{"name":"stderr","output_type":"stream","text":["Loading extension module test_ext_v4...\n"]}],"source":["# G++-9 supports C++17 by default. To use C++20 with g++-9, you need to specify the -std=c++2a flag. For example, to compile a C++20 program with g++-9, you would use the following command:\n","# https://stackoverflow.com/questions/75470181/cmake-knows-std-20-but-g9-doesnt\n","# Kaggle is using g++-9 so the above issues arose.\n","# after the //CHECK_INPUT(input); is commented, the code executed.\n","# even adding -std=c++20 did not make a difference\n","# adding build_directory='.' is important, else it errors out as the rest of the file-system is not writable\n","module = torch.utils.cpp_extension.load_inline(\n","    name=\"test_ext\", cpp_sources=cpp_src, cuda_sources=cuda_src, \n","    functions=['rgb_to_grayscale', 'rgb_to_grayscale_out'], extra_cuda_cflags=['--ptxas-options=-v -std=c++20'], verbose=True,\n","build_directory='.')"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T02:32:40.806418Z","iopub.status.busy":"2024-05-18T02:32:40.805678Z","iopub.status.idle":"2024-05-18T02:32:40.968647Z","shell.execute_reply":"2024-05-18T02:32:40.967674Z","shell.execute_reply.started":"2024-05-18T02:32:40.806372Z"},"trusted":true},"outputs":[],"source":["n = 2048\n","# create a 3D 2048 px * 2048 px \n","t = torch.randint(0, 256, (3, n, n), dtype=torch.uint8, device=\"cuda\")"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T02:32:43.414570Z","iopub.status.busy":"2024-05-18T02:32:43.414152Z","iopub.status.idle":"2024-05-18T02:32:43.420957Z","shell.execute_reply":"2024-05-18T02:32:43.419903Z","shell.execute_reply.started":"2024-05-18T02:32:43.414542Z"},"trusted":true},"outputs":[],"source":["out = module.rgb_to_grayscale(t)\n","# hmm, there is synchronize in python too..\n","torch.cuda.synchronize()"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T02:32:48.158667Z","iopub.status.busy":"2024-05-18T02:32:48.157959Z","iopub.status.idle":"2024-05-18T02:32:48.708106Z","shell.execute_reply":"2024-05-18T02:32:48.707143Z","shell.execute_reply.started":"2024-05-18T02:32:48.158636Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["54.42138 µs\n"]}],"source":["import time\n","t0 = time.perf_counter_ns()\n","\n","for i in range(10_000):\n","    module.rgb_to_grayscale_out(out, t)\n","\n","torch.cuda.synchronize()\n","t1 = time.perf_counter_ns()\n","\n","print((t1-t0) / 10_000 / 1_000, \"µs\") "]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T02:32:53.618734Z","iopub.status.busy":"2024-05-18T02:32:53.617861Z","iopub.status.idle":"2024-05-18T02:32:59.420613Z","shell.execute_reply":"2024-05-18T02:32:59.419656Z","shell.execute_reply.started":"2024-05-18T02:32:53.618700Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["STAGE:2024-05-18 02:32:55 34:34 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n","STAGE:2024-05-18 02:32:56 34:34 ActivityProfilerController.cpp:318] Completed Stage: Collection\n","STAGE:2024-05-18 02:32:56 34:34 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n"]},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n","                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n","-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n","                                       cudaLaunchKernel        10.73%      64.400ms        10.73%      64.400ms       6.440us       0.000us         0.00%       0.000us       0.000us         10000  \n","rgb_to_grayscale_kernel(unsigned char*, unsigned cha...         0.00%       0.000us         0.00%       0.000us       0.000us     655.917ms       100.00%     655.917ms      65.592us         10000  \n","                                  cudaDeviceSynchronize        89.27%     535.777ms        89.27%     535.777ms      53.572us       0.000us         0.00%       0.000us       0.000us         10001  \n","-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n","Self CPU time total: 600.177ms\n","Self CUDA time total: 655.917ms\n","\n"]}],"source":["with torch.profiler.profile() as prof:\n","    for i in range(10_000):\n","        module.rgb_to_grayscale_out(out, t)\n","        torch.cuda.synchronize()\n","\n","print(prof.key_averages().table())"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T02:33:03.629925Z","iopub.status.busy":"2024-05-18T02:33:03.628829Z","iopub.status.idle":"2024-05-18T02:33:03.645608Z","shell.execute_reply":"2024-05-18T02:33:03.644410Z","shell.execute_reply.started":"2024-05-18T02:33:03.629879Z"},"trusted":true},"outputs":[],"source":["# gelu as fusion example\n","def gelu(x):\n","    return 0.5 * x * (1+ torch.tanh((2/torch.pi)**0.5 * (x+0.044715 * x**3)))\n","\n","x = torch.randn(1024, 1024, device=\"cuda\")"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T02:33:07.018873Z","iopub.status.busy":"2024-05-18T02:33:07.018473Z","iopub.status.idle":"2024-05-18T02:33:24.141892Z","shell.execute_reply":"2024-05-18T02:33:24.140917Z","shell.execute_reply.started":"2024-05-18T02:33:07.018842Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["174 µs ± 590 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n","35.5 µs ± 85.6 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"]}],"source":["%timeit gelu(x); torch.cuda.synchronize()\n","%timeit torch.nn.functional.gelu(x, approximate='tanh'); torch.cuda.synchronize()"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T02:34:22.029196Z","iopub.status.busy":"2024-05-18T02:34:22.028801Z","iopub.status.idle":"2024-05-18T02:35:31.483057Z","shell.execute_reply":"2024-05-18T02:35:31.482048Z","shell.execute_reply.started":"2024-05-18T02:34:22.029166Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["The input conditions for extension module test_ext_gelu have changed. Bumping to version 1 and re-building as test_ext_gelu_v1...\n","Detected CUDA files, patching ldflags\n","Emitting ninja build file ./build.ninja...\n","Building extension module test_ext_gelu_v1...\n","Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"]},{"name":"stdout","output_type":"stream","text":["[1/3] /usr/lib/ccache/g++-9 -MMD -MF main.o.d -DTORCH_EXTENSION_NAME=test_ext_gelu_v1 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1013\\\" -isystem /opt/conda/lib/python3.10/site-packages/torch/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++17 -c /kaggle/working/main.cpp -o main.o \n","[2/3] /usr/local/cuda/bin/nvcc  -ccbin /usr/lib/ccache/gcc-9 -DTORCH_EXTENSION_NAME=test_ext_gelu_v1 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1013\\\" -isystem /opt/conda/lib/python3.10/site-packages/torch/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 --compiler-options '-fPIC' --ptxas-options=-v -std=c++17 -c /kaggle/working/cuda.cu -o cuda.cuda.o \n","ptxas info    : 1 bytes gmem\n","ptxas info    : Compiling entry function '_Z14my_gelu_kernelPfS_i' for 'sm_60'\n","ptxas info    : Function properties for _Z14my_gelu_kernelPfS_i\n","    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","ptxas info    : Used 8 registers, 340 bytes cmem[0], 32 bytes cmem[2]\n","[3/3] /usr/lib/ccache/g++-9 main.o cuda.cuda.o -shared -L/opt/conda/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o test_ext_gelu_v1.so\n"]},{"name":"stderr","output_type":"stream","text":["Loading extension module test_ext_gelu_v1...\n"]}],"source":["cuda_src = cuda_begin + r'''\n","__global__ void my_gelu_kernel(float* out, float* inp, int n) {\n","    int i = blockIdx.x*blockDim.x + threadIdx.x;\n","    if (i >= n) return;\n","    float x = inp[i];\n","    out[i] = 0.5f * x * (1.0f + tanhf(sqrtf(2.0f/3.141592653589793f) * (x + 0.044715f * (x * x * x))));\n","}\n","\n","torch::Tensor my_gelu_out(torch::Tensor output, const torch::Tensor& inp) {\n","    //CHECK_INPUT(inp);\n","    int n = inp.numel();\n","    TORCH_CHECK((output.sizes() == inp.sizes())  || (output.device() == inp.device())\n","                || (output.scalar_type() == inp.scalar_type()));\n","    int threads = 256;\n","    my_gelu_kernel<<<cdiv(n, threads), threads>>>(\n","        output.data_ptr<float>(), inp.data_ptr<float>(), n);\n","    C10_CUDA_KERNEL_LAUNCH_CHECK();\n","    return output;\n","}\n","\n","torch::Tensor my_gelu(const torch::Tensor& inp) {\n","    //CHECK_INPUT(inp);\n","    auto output = torch::empty_like(inp);\n","    my_gelu_out(output, inp);\n","    return output;\n","}\n","'''\n","\n","cpp_src = \"\"\"\n","torch::Tensor my_gelu(const torch::Tensor& inp);\n","torch::Tensor my_gelu_out(torch::Tensor output, const torch::Tensor& inp);\n","\"\"\"\n","\n","import os\n","os.environ['CXX'] = '/usr/lib/ccache/g++-9'\n","os.environ['CC'] = '/usr/lib/ccache/gcc-9'\n","\n","gelu_module = torch.utils.cpp_extension.load_inline(\n","    \"test_ext_gelu\", cpp_src, cuda_src, \n","    functions=['my_gelu', 'my_gelu_out'], extra_cuda_cflags=['--ptxas-options=-v'], verbose=True, build_directory='.')"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T02:36:09.368708Z","iopub.status.busy":"2024-05-18T02:36:09.368309Z","iopub.status.idle":"2024-05-18T02:36:09.632741Z","shell.execute_reply":"2024-05-18T02:36:09.631811Z","shell.execute_reply.started":"2024-05-18T02:36:09.368678Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor(2.3842e-07, device='cuda:0')"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["(gelu_module.my_gelu(x) - gelu(x)).abs().max()"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T02:36:11.323379Z","iopub.status.busy":"2024-05-18T02:36:11.322974Z","iopub.status.idle":"2024-05-18T02:36:14.877319Z","shell.execute_reply":"2024-05-18T02:36:14.876352Z","shell.execute_reply.started":"2024-05-18T02:36:11.323346Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["43.2 µs ± 1.19 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"]}],"source":["%timeit gelu_module.my_gelu(x); torch.cuda.synchronize()"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T02:36:49.054193Z","iopub.status.busy":"2024-05-18T02:36:49.053555Z","iopub.status.idle":"2024-05-18T02:37:56.571074Z","shell.execute_reply":"2024-05-18T02:37:56.569984Z","shell.execute_reply.started":"2024-05-18T02:36:49.054161Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["The input conditions for extension module test_ext_empty have changed. Bumping to version 1 and re-building as test_ext_empty_v1...\n","Detected CUDA files, patching ldflags\n","Emitting ninja build file ./build.ninja...\n","Building extension module test_ext_empty_v1...\n","Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"]},{"name":"stdout","output_type":"stream","text":["[1/3] /usr/lib/ccache/g++-9 -MMD -MF main.o.d -DTORCH_EXTENSION_NAME=test_ext_empty_v1 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1013\\\" -isystem /opt/conda/lib/python3.10/site-packages/torch/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++17 -c /kaggle/working/main.cpp -o main.o \n","[2/3] /usr/local/cuda/bin/nvcc  -ccbin /usr/lib/ccache/gcc-9 -DTORCH_EXTENSION_NAME=test_ext_empty_v1 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1013\\\" -isystem /opt/conda/lib/python3.10/site-packages/torch/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 --compiler-options '-fPIC' --ptxas-options=-v -std=c++17 -c /kaggle/working/cuda.cu -o cuda.cuda.o \n","ptxas info    : 1 bytes gmem\n","ptxas info    : Compiling entry function '_Z15my_empty_kernelPfS_i' for 'sm_60'\n","ptxas info    : Function properties for _Z15my_empty_kernelPfS_i\n","    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","ptxas info    : Used 2 registers, 340 bytes cmem[0]\n","[3/3] /usr/lib/ccache/g++-9 main.o cuda.cuda.o -shared -L/opt/conda/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o test_ext_empty_v1.so\n"]},{"name":"stderr","output_type":"stream","text":["Loading extension module test_ext_empty_v1...\n"]}],"source":["# empty kernel to look at the latency\n","\n","cuda_src = cuda_begin + r'''\n","__global__ void my_empty_kernel(float* out, float* inp, int n) {\n","}\n","\n","torch::Tensor my_empty_out(torch::Tensor output, const torch::Tensor& inp) {\n","    // CHECK_INPUT(inp);\n","    int n = inp.numel(); // calculate num of elements in the tensor\n","    TORCH_CHECK((output.sizes() == inp.sizes())  || (output.device() == inp.device())\n","                || (output.scalar_type() == inp.scalar_type()));\n","    int threads = 256;\n","    my_empty_kernel<<<cdiv(n, threads), threads>>>(\n","        output.data_ptr<float>(), inp.data_ptr<float>(), n);\n","    C10_CUDA_KERNEL_LAUNCH_CHECK();\n","    return output;\n","}\n","\n","torch::Tensor my_empty(const torch::Tensor& inp) {\n","    // CHECK_INPUT(inp);\n","    auto output = torch::empty_like(inp);\n","    my_empty_out(output, inp);\n","    return output;\n","}\n","'''\n","\n","cpp_src = \"\"\"\n","torch::Tensor my_empty(const torch::Tensor& inp);\n","torch::Tensor my_empty_out(torch::Tensor output, const torch::Tensor& inp);\n","\"\"\"\n","\n","import os\n","os.environ['CXX'] = '/usr/lib/ccache/g++-9'\n","os.environ['CC'] = '/usr/lib/ccache/gcc-9'\n","\n","empty_module = torch.utils.cpp_extension.load_inline(\n","    \"test_ext_empty\", cpp_src, cuda_src, \n","    functions=['my_empty', 'my_empty_out'], extra_cuda_cflags=['--ptxas-options=-v'], verbose=True, build_directory='.')"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T02:38:01.356733Z","iopub.status.busy":"2024-05-18T02:38:01.355988Z","iopub.status.idle":"2024-05-18T02:38:06.568963Z","shell.execute_reply":"2024-05-18T02:38:06.568005Z","shell.execute_reply.started":"2024-05-18T02:38:01.356698Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["25.9 µs ± 144 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"]},{"name":"stderr","output_type":"stream","text":["STAGE:2024-05-18 02:38:03 34:34 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n","STAGE:2024-05-18 02:38:03 34:34 ActivityProfilerController.cpp:318] Completed Stage: Collection\n","STAGE:2024-05-18 02:38:03 34:34 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n"]},{"name":"stdout","output_type":"stream","text":["----------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n","                                    Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n","----------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n","                        cudaLaunchKernel        72.88%      56.963ms        72.88%      56.963ms       5.696us       0.000us         0.00%       0.000us       0.000us         10000  \n","    my_empty_kernel(float*, float*, int)         0.00%       0.000us         0.00%       0.000us       0.000us     116.967ms       100.00%     116.967ms      11.697us         10000  \n","                   cudaDeviceSynchronize        27.12%      21.194ms        27.12%      21.194ms       2.119us       0.000us         0.00%       0.000us       0.000us         10001  \n","----------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n","Self CPU time total: 78.157ms\n","Self CUDA time total: 116.967ms\n","\n"]}],"source":["%timeit empty_module.my_empty_out(x, x); torch.cuda.synchronize()\n","\n","with torch.profiler.profile() as prof:\n","    for i in range(10_000):\n","        empty_module.my_empty_out(x, x)\n","        torch.cuda.synchronize()\n","\n","print(prof.key_averages().table())"]},{"cell_type":"markdown","metadata":{},"source":["https://stackoverflow.com/questions/7024615/putting-a-for-loop-in-a-cuda-kernel\n","https://forums.developer.nvidia.com/t/cuda-kernel-for-loop-performance/81165/8\n","https://developer.nvidia.com/blog/cuda-pro-tip-write-flexible-kernels-grid-stride-loops/"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T02:38:34.753902Z","iopub.status.busy":"2024-05-18T02:38:34.753230Z","iopub.status.idle":"2024-05-18T02:39:45.804496Z","shell.execute_reply":"2024-05-18T02:39:45.803487Z","shell.execute_reply.started":"2024-05-18T02:38:34.753868Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Detected CUDA files, patching ldflags\n","Emitting ninja build file ./build.ninja...\n","Building extension module test_ext_simple_matmul...\n","Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"]},{"name":"stdout","output_type":"stream","text":["[1/3] /usr/lib/ccache/g++-9 -MMD -MF main.o.d -DTORCH_EXTENSION_NAME=test_ext_simple_matmul -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1013\\\" -isystem /opt/conda/lib/python3.10/site-packages/torch/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++17 -c /kaggle/working/main.cpp -o main.o \n","[2/3] /usr/local/cuda/bin/nvcc  -ccbin /usr/lib/ccache/gcc-9 -DTORCH_EXTENSION_NAME=test_ext_simple_matmul -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1013\\\" -isystem /opt/conda/lib/python3.10/site-packages/torch/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 --compiler-options '-fPIC' --ptxas-options=-v -std=c++17 -c /kaggle/working/cuda.cu -o cuda.cuda.o \n","ptxas info    : 1 bytes gmem\n","ptxas info    : Compiling entry function '_Z15simple_matmul_kPfS_S_iii' for 'sm_60'\n","ptxas info    : Function properties for _Z15simple_matmul_kPfS_S_iii\n","    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","ptxas info    : Used 32 registers, 356 bytes cmem[0]\n","[3/3] /usr/lib/ccache/g++-9 main.o cuda.cuda.o -shared -L/opt/conda/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o test_ext_simple_matmul.so\n"]},{"name":"stderr","output_type":"stream","text":["Loading extension module test_ext_simple_matmul...\n"]}],"source":["cuda_src = cuda_begin + r'''\n","__global__ void simple_matmul_k(float* m, float* n, float* out, int h, int w, int k) {\n","    int r = blockIdx.y*blockDim.y + threadIdx.y;\n","    int c = blockIdx.x*blockDim.x + threadIdx.x;\n","\n","    if (r>=h || c>=w) return;\n","    float o = 0;\n","    for (int i = 0; i<k; ++i) o += m[r*k+i] * n[i*w+c]; // need to review how this loop will execute\n","    out[r*w+c] = o;\n","}\n","\n","torch::Tensor simple_matmul(const torch::Tensor& m, const torch::Tensor& n) {\n","    // CHECK_INPUT(m); CHECK_INPUT(n);\n","    int h = m.size(0);\n","    int w = n.size(1);\n","    int k = m.size(1);\n","    TORCH_CHECK(k==n.size(0), \"Size mismatch!\");\n","    auto output = torch::zeros({h, w}, m.options());\n","\n","    dim3 tpb(16,16);\n","    dim3 blocks(cdiv(w, tpb.x), cdiv(h, tpb.y));\n","    simple_matmul_k<<<blocks, tpb>>>(\n","        m.data_ptr<float>(), n.data_ptr<float>(), output.data_ptr<float>(), h, w, k);\n","    C10_CUDA_KERNEL_LAUNCH_CHECK();\n","    return output;\n","}\n","'''\n","\n","cpp_src = \"\"\"\n","torch::Tensor simple_matmul(const torch::Tensor& m, const torch::Tensor& n);\n","\"\"\"\n","\n","simple_matmul_module = torch.utils.cpp_extension.load_inline(\n","    \"test_ext_simple_matmul\", cpp_src, cuda_src, \n","    functions=['simple_matmul'], extra_cuda_cflags=['--ptxas-options=-v'], verbose=True, build_directory='.')"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T02:39:45.806567Z","iopub.status.busy":"2024-05-18T02:39:45.806271Z","iopub.status.idle":"2024-05-18T02:40:20.045357Z","shell.execute_reply":"2024-05-18T02:40:20.044322Z","shell.execute_reply.started":"2024-05-18T02:39:45.806540Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["4.21 ms ± 1.37 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"]},{"data":{"text/plain":["tensor(0.0002, device='cuda:0')"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["a = torch.randn(1024, 1024, device=\"cuda\")\n","b = torch.randn(1024, 1024, device=\"cuda\")\n","%timeit simple_matmul_module.simple_matmul(a, b)\n","\n","(simple_matmul_module.simple_matmul(a, b) - a@b).abs().max()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T02:40:20.061564Z","iopub.status.busy":"2024-05-18T02:40:20.061238Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Detected CUDA files, patching ldflags\n","Emitting ninja build file ./build.ninja...\n","Building extension module test_ext_tiled_matmul...\n","Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"]},{"name":"stdout","output_type":"stream","text":["[1/3] /usr/lib/ccache/g++-9 -MMD -MF main.o.d -DTORCH_EXTENSION_NAME=test_ext_tiled_matmul -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1013\\\" -isystem /opt/conda/lib/python3.10/site-packages/torch/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++17 -c /kaggle/working/main.cpp -o main.o \n"]}],"source":["cuda_src = cuda_begin + r\"\"\"\n","constexpr int TILE_SIZE = 16;\n","\n","__global__ void tiled_matmul_kernel(float* out, float* M, float* N, int h, int w, int k) {\n","  __shared__ float M_tile[TILE_SIZE][TILE_SIZE];\n","  __shared__ float N_tile[TILE_SIZE][TILE_SIZE];\n","  \n","  // idxes into tile\n","  int ir = threadIdx.y;\n","  int ic = threadIdx.x;\n","  \n","  int r = blockIdx.y * blockDim.y + threadIdx.y;\n","  int c = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","  // note: cannot just exit if we want to do padding!\n","  \n","  float res = 0.0f;\n","  for (int K_tileidx = 0; K_tileidx < (k + TILE_SIZE -1) / TILE_SIZE; K_tileidx++) {\n","    // note how threadIdx.x is the fastes moving bit --> coalesced memory access\n","    M_tile[ir][ic] = (((r < h) && (K_tileidx * TILE_SIZE + ic < k)) ? M[r * k + K_tileidx * TILE_SIZE + ic] : 0.f);\n","    N_tile[ir][ic] = ((((K_tileidx * TILE_SIZE + ir) < k) && (c < w)) ? N[(K_tileidx * TILE_SIZE + ir) * w + c] : 0.f);\n","    //M_tile[ir][ic] = M[r * k + K_tileidx * TILE_SIZE + ic];\n","    //N_tile[ir][ic] = N[(K_tileidx * TILE_SIZE + ir) * w + c];\n","    __syncthreads();\n","    for (int idx = 0; idx < TILE_SIZE; idx++) {\n","       res += M_tile[ir][idx] * N_tile[idx][ic];\n","    }\n","    __syncthreads(); // important! (why?)\n","  }\n","  if ((r < h) && (c < w)) {\n","    out[r * w + c] = res;\n","  }\n","}\n","\n","torch::Tensor tiled_matmul(const torch::Tensor& m, const torch::Tensor& n) {\n","    // CHECK_INPUT(m); CHECK_INPUT(n);\n","    int h = m.size(0);\n","    int w = n.size(1);\n","    int k = m.size(1);\n","    TORCH_CHECK(k==n.size(0), \"Size mismatch\");\n","    //TORCH_CHECK((k % TILE_SIZE == 0) && (h % TILE_SIZE == 0) && (w % TILE_SIZE == 0), \"Padding not done\");\n","    auto output = torch::empty({h, w}, m.options());\n","\n","    dim3 tpb(TILE_SIZE, TILE_SIZE);\n","    dim3 blocks(cdiv(w, tpb.x), cdiv(h, tpb.y));\n","    tiled_matmul_kernel<<<blocks, tpb>>>(\n","        output.data_ptr<float>(), m.data_ptr<float>(), n.data_ptr<float>(), h, w, k);\n","    C10_CUDA_KERNEL_LAUNCH_CHECK();\n","    return output;\n","}\n","\n","\"\"\"\n","cpp_src = \"\"\"\n","torch::Tensor tiled_matmul(const torch::Tensor& m, const torch::Tensor& n);\n","\"\"\"\n","\n","tiled_matmul_module = torch.utils.cpp_extension.load_inline(\n","    \"test_ext_tiled_matmul\", cpp_src, cuda_src, \n","    functions=['tiled_matmul'], extra_cuda_cflags=['--ptxas-options=-v'], verbose=True, build_directory='.')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%timeit tiled_matmul_module.tiled_matmul(a, b)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["aa = torch.randn(500, 200, device=\"cuda\")\n","bb = torch.randn(200, 1000, device=\"cuda\")\n","\n","\n","(tiled_matmul_module.tiled_matmul(aa, bb) - aa@bb).abs().max()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
