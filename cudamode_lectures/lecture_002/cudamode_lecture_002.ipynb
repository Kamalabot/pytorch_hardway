{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wiLMWv0Hvi8I"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision ninja > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ninja"
      ],
      "metadata": {
        "id": "CDR2O7LcQJIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import torch\n",
        "from torchvision.io import read_image, write_png\n",
        "from torch.utils.cpp_extension import load_inline"
      ],
      "metadata": {
        "id": "nJzQEleWv2Tb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### mean_filter_kernel"
      ],
      "metadata": {
        "id": "2T6iVHnk2LFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_source = \"\"\"\n",
        "#include <c10/cuda/CUDAException.h>\n",
        "#include <c10/cuda/CUDAStream.h>\n",
        "\n",
        "\n",
        "__global__\n",
        "void mean_filter_kernel(unsigned char* output, unsigned char* input, int width, int height, int radius) {\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int channel = threadIdx.z;\n",
        "\n",
        "    int baseOffset = channel * height * width;\n",
        "    if (col < width && row < height) {\n",
        "\n",
        "        int pixVal = 0;\n",
        "        int pixels = 0;\n",
        "\n",
        "        for (int blurRow=-radius; blurRow <= radius; blurRow += 1) {\n",
        "            for (int blurCol=-radius; blurCol <= radius; blurCol += 1) {\n",
        "                int curRow = row + blurRow;\n",
        "                int curCol = col + blurCol;\n",
        "                if (curRow >= 0 && curRow < height && curCol >=0 && curCol < width) {\n",
        "                    pixVal += input[baseOffset + curRow * width + curCol];\n",
        "                    pixels += 1;\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        output[baseOffset + row * width + col] = (unsigned char)(pixVal / pixels);\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "// helper function for ceiling unsigned integer division\n",
        "inline unsigned int cdiv(unsigned int a, unsigned int b) {\n",
        "  return (a + b - 1) / b;\n",
        "}\n",
        "\n",
        "// this is a cpp function, which is called as cpp_source\n",
        "torch::Tensor mean_filter(torch::Tensor image, int radius) {\n",
        "    assert(image.device().type() == torch::kCUDA);\n",
        "    assert(image.dtype() == torch::kByte);\n",
        "    assert(radius > 0);\n",
        "\n",
        "    const auto channels = image.size(0);\n",
        "    const auto height = image.size(1);\n",
        "    const auto width = image.size(2);\n",
        "\n",
        "    auto result = torch::empty_like(image);\n",
        "\n",
        "    dim3 threads_per_block(16, 16, channels);\n",
        "    dim3 number_of_blocks(\n",
        "        cdiv(width, threads_per_block.x),\n",
        "        cdiv(height, threads_per_block.y)\n",
        "    );\n",
        "\n",
        "    mean_filter_kernel<<<number_of_blocks, threads_per_block, 0, torch::cuda::getCurrentCUDAStream()>>>(\n",
        "        result.data_ptr<unsigned char>(),\n",
        "        image.data_ptr<unsigned char>(),\n",
        "        width,\n",
        "        height,\n",
        "        radius\n",
        "    );\n",
        "\n",
        "    // check CUDA error status (calls cudaGetLastError())\n",
        "    C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
        "\n",
        "    return result;\n",
        "}\"\"\""
      ],
      "metadata": {
        "id": "tz2T3bzxv2aT"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# deleting files with python in current path.\n",
        "import os\n",
        "\n",
        "def clear_cudafiles(path_str):\n",
        "  \"\"\"Clears the files alone in pwd\"\"\"\n",
        "  objs = os.listdir(path_str)\n",
        "  for obj in objs:\n",
        "    if os.path.isfile(os.path.join(path_str, obj)):\n",
        "      os.remove(os.path.join(path_str, obj))\n",
        "  print(\"Files deleted. Refresh...\")"
      ],
      "metadata": {
        "id": "TF5kZyJj7C4G"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compile_extension(cuda_source: str, cpp_source: str,\n",
        "                      ext_name: str, call_funcs: list,\n",
        "                      build_dir='.'):\n",
        "  clear_cudafiles(path_str=build_dir)\n",
        "  your_extension = load_inline(\n",
        "      name=ext_name,\n",
        "      cpp_sources=cpp_source,\n",
        "      cuda_sources=cuda_source,\n",
        "      functions=call_funcs,\n",
        "      with_cuda=True,\n",
        "      extra_cuda_cflags=['-O2 -arch=sm_75 -std=c++20'],  # sm_75 is chosen for turning arch\n",
        "      build_directory='.',\n",
        "      )\n",
        "  return your_extension\n",
        "# https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html?highlight=virtual%20arch#virtual-architectures\n",
        "# Note the cuda C++ guide is different to NVCC guide provided above"
      ],
      "metadata": {
        "id": "-jw2ydrav2fr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cpp_source = \"torch::Tensor mean_filter(torch::Tensor image, int radius);\"\n",
        "\n",
        "rgb_extension = compile_extension(cuda_source=cuda_source, cpp_source=cpp_source, ext_name=\"rgb_blur\", call_funcs=['mean_filter'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjyZAQrrv2kr",
        "outputId": "c395cb42-64b7-4c97-a16f-e5b8a3bc7afe"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files deleted. Refresh...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = read_image(\"Grace_Hopper.jpg\").contiguous().cuda()\n",
        "assert x.dtype == torch.uint8\n",
        "print(\"Input image:\", x.shape, x.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DAKQ86yv2pc",
        "outputId": "1c6504c7-c31b-42e0-95c5-61301cba6832"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input image: torch.Size([3, 606, 517]) torch.uint8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = rgb_extension.mean_filter(x, 8)\n",
        "\n",
        "print(\"Output image:\", y.shape, y.dtype)\n",
        "\n",
        "write_png(y.cpu(), \"output.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgvvv5Q91X5O",
        "outputId": "072880c4-1947-4cf3-a465-7ee134e958d8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output image: torch.Size([3, 606, 517]) torch.uint8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### vector add kernel"
      ],
      "metadata": {
        "id": "tyES5x142Jwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_source = \"\"\"\n",
        "#include <cuda.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "// compute vector sum C = A + B\n",
        "// each thread peforms one pair-wise addition\n",
        "\n",
        "__global__ void vecAddKernel(float *A, float *B, float *C, int n) {\n",
        "  printf(\"threadIdx: %d \", threadIdx.x);\n",
        "  printf(\"blockIdx: %d\", blockIdx.x);\n",
        "  printf(\"blockDim: %d\", blockDim.x);\n",
        "  int i = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "  if (i < n) {\n",
        "    C[i] = A[i] + B[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "// https://stackoverflow.com/questions/14038589/what-is-the-canonical-way-to-check-for-errors-using-the-cuda-runtime-api\n",
        "\n",
        "/*\n",
        "#define gpuErrchk(ans) { gpuAssert((ans), __FILE__, __LINE__); }\n",
        "inline void gpuAssert(cudaError_t code, const char *file, int line, bool abort = true) {\n",
        "  if (code != cudaSuccess) {\n",
        "    fprintf(stderr, \"GPUassert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\n",
        "    if (abort) {\n",
        "      exit(code);\n",
        "    }\n",
        "  }\n",
        "}\n",
        "*/\n",
        "\n",
        "inline unsigned int cdiv(unsigned int a, unsigned int b) {\n",
        "  return (a + b - 1) / b;\n",
        "}\n",
        "\n",
        "// following is the cpp function\n",
        "void vecAdd(float *A, float *B, float *C, int n) {\n",
        "  float *A_d, *B_d, *C_d;\n",
        "  size_t size = n * sizeof(float);\n",
        "\n",
        "  cudaMalloc((void **)&A_d, size);\n",
        "  cudaMalloc((void **)&B_d, size);\n",
        "  cudaMalloc((void **)&C_d, size);\n",
        "\n",
        "  cudaMemcpy(A_d, A, size, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(B_d, B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "  const unsigned int numThreads = 256;\n",
        "  unsigned int numBlocks = cdiv(n, numThreads);\n",
        "\n",
        "  vecAddKernel<<<numBlocks, numThreads>>>(A_d, B_d, C_d, n);\n",
        "  // gpuErrchk(cudaPeekAtLastError());\n",
        "  // gpuErrchk(cudaDeviceSynchronize());\n",
        "\n",
        "  cudaMemcpy(C, C_d, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "  cudaFree(A_d);\n",
        "  cudaFree(B_d);\n",
        "  cudaFree(C_d);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "  const int n = 1000;\n",
        "  float A[n];\n",
        "  float B[n];\n",
        "  float C[n];\n",
        "\n",
        "  // generate some dummy vectors to add\n",
        "  for (int i = 0; i < n; i += 1) {\n",
        "    A[i] = float(i);\n",
        "    B[i] = A[i] / 1000.0f;\n",
        "  }\n",
        "  std::cout << \"created input vectors\";\n",
        "  vecAdd(A, B, C, n);\n",
        "  std::cout << \"Call to vecAdd done. Printing results\";\n",
        "\n",
        "  // print result\n",
        "  for (int i = 0; i < n; i += 1) {\n",
        "    if (i > 0) {\n",
        "      std::cout << \", \";\n",
        "      if (i % 10 == 0) {\n",
        "        std::cout << std::endl;\n",
        "      }\n",
        "    }\n",
        "    std::cout << C[i];\n",
        "  }\n",
        "  return 100;\n",
        "}\"\"\""
      ],
      "metadata": {
        "id": "gmykkhkv2JSV"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SOME Observation when compiling through the load_inline function\n",
        "\n",
        "- printf() and \"\\n\" needs to be avoided, because they get parsed differently when cuda.cu file is created below. Usage of std::out / std::endl will be better option.\n",
        "\n",
        "- The function that calls CUDA Kernel is embedded inside a C++ function, which is to be called with correct inputs from python environment.\n",
        "\n",
        "- function writes out the cuda.cu file, along with seperate main.cpp file which contains the below code.\n",
        "\n",
        "  ```\n",
        "  #include <torch/extension.h>\n",
        "\n",
        "  torch::Tensor mean_filter(torch::Tensor image, int radius);\n",
        "\n",
        "  PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {\n",
        "    m.def(\"mean_filter\", torch::wrap_pybind_function(mean_filter), \"mean_filter\");\n",
        "  }\n",
        "  ```\n",
        "- When the extension needs to be used, the name of the variable containing the extension object, followed by the .func_name in the above code snippet needs to be used."
      ],
      "metadata": {
        "id": "Fgvv3EdzHSmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cpp_source = \"int main();\""
      ],
      "metadata": {
        "id": "KZISnNxu4QBu"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_add_ext = compile_extension(cuda_source=cuda_source,\n",
        "                                   cpp_source=cpp_source,\n",
        "                                   ext_name='vector_add',\n",
        "                                   call_funcs=['main'])\n",
        "# the compiling extension failed, however the cuda code itself ran successfully."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkbQ_Fxc4RM1",
        "outputId": "b4b2402d-66fc-43a8-fe74-936e8931e7b7"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files deleted. Refresh...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qY3ujzGME2Sf",
        "outputId": "ecbb0efa-52fd-4404-e3d9-2e209853a120"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "build.ninja  cuda.cu  cuda.cuda.o  main.cpp  main.o  sample_data  vector_add_v7.so\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o vector_addition -arch=sm_75 -O2 vector_addition.cu"
      ],
      "metadata": {
        "id": "KKmuKeISBTt_"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./vector_addition"
      ],
      "metadata": {
        "id": "wOjWXQhwFxDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ncu -o vecadd_profile vector_addition"
      ],
      "metadata": {
        "id": "DF87XEMqF5yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./vector_addition"
      ],
      "metadata": {
        "id": "SMIaLzKvBTo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### rgb_to_grayscale kernel"
      ],
      "metadata": {
        "id": "e7iLgNHYQWdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_source = \"\"\"\n",
        "#include <c10/cuda/CUDAException.h>\n",
        "#include <c10/cuda/CUDAStream.h>\n",
        "\n",
        "\n",
        "__global__\n",
        "void rgb_to_grayscale_kernel(unsigned char* output, unsigned char* input, int width, int height) {\n",
        "    const int channels = 3;\n",
        "\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "    if (col < width && row < height) {\n",
        "        int outputOffset = row * width + col;\n",
        "        int inputOffset = (row * width + col) * channels;\n",
        "\n",
        "        unsigned char r = input[inputOffset + 0];   // red\n",
        "        unsigned char g = input[inputOffset + 1];   // green\n",
        "        unsigned char b = input[inputOffset + 2];   // blue\n",
        "\n",
        "        output[outputOffset] = (unsigned char)(0.21f * r + 0.71f * g + 0.07f * b);\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "// helper function for ceiling unsigned integer division\n",
        "inline unsigned int cdiv(unsigned int a, unsigned int b) {\n",
        "  return (a + b - 1) / b;\n",
        "}\n",
        "\n",
        "\n",
        "torch::Tensor rgb_to_grayscale(torch::Tensor image) {\n",
        "    assert(image.device().type() == torch::kCUDA);\n",
        "    assert(image.dtype() == torch::kByte);\n",
        "\n",
        "    const auto height = image.size(0);\n",
        "    const auto width = image.size(1);\n",
        "\n",
        "    auto result = torch::empty({height, width, 1}, torch::TensorOptions().dtype(torch::kByte).device(image.device()));\n",
        "\n",
        "    dim3 threads_per_block(16, 16);     // using 256 threads per block\n",
        "    dim3 number_of_blocks(cdiv(width, threads_per_block.x),\n",
        "                          cdiv(height, threads_per_block.y));\n",
        "\n",
        "    rgb_to_grayscale_kernel<<<number_of_blocks, threads_per_block, 0, torch::cuda::getCurrentCUDAStream()>>>(\n",
        "        result.data_ptr<unsigned char>(),\n",
        "        image.data_ptr<unsigned char>(),\n",
        "        width,\n",
        "        height\n",
        "    );\n",
        "\n",
        "    // check CUDA error status (calls cudaGetLastError())\n",
        "    C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
        "\n",
        "    return result;\n",
        "}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "xXgNhNmcObBS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cpp_source = \"torch::Tensor rgb_to_grayscale(torch::Tensor image);\""
      ],
      "metadata": {
        "id": "BLVEfN5oOa9N"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rgb_to_gs = compile_extension(cuda_source=cuda_source,\n",
        "                              cpp_source=cpp_source,\n",
        "                              ext_name='rgb_to_gs',\n",
        "                              call_funcs=['rgb_to_grayscale'])"
      ],
      "metadata": {
        "id": "hg2WFFVfOa6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rgb_to_gs.rgb_to_grayscale()"
      ],
      "metadata": {
        "id": "ht_MCg9qOa3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = read_image(\"Grace_Hopper.jpg\").permute(1, 2, 0).cuda()\n",
        "print(\"mean:\", x.float().mean())\n",
        "print(\"Input image:\", x.shape, x.dtype)\n",
        "\n",
        "assert x.dtype == torch.uint8"
      ],
      "metadata": {
        "id": "lGOasHDOOa1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = rgb_to_gs.rgb_to_grayscale(x)\n",
        "\n",
        "print(\"Output image:\", y.shape, y.dtype)\n",
        "print(\"mean\", y.float().mean())\n",
        "\n",
        "write_png(y.permute(2, 0, 1).cpu(), \"output.png\")"
      ],
      "metadata": {
        "id": "UpTSrpy2Oaxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mJJwRzZvOavJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9y4mmnBuOasc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l_Ujg9xQOap8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P9P4zYcVOamq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}