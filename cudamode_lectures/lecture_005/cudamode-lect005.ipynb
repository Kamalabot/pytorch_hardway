{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Setup","metadata":{}},{"cell_type":"code","source":"!pip install ninja wurlitzer >> /dev/null","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:34:42.562189Z","iopub.execute_input":"2024-05-19T00:34:42.562818Z","iopub.status.idle":"2024-05-19T00:34:56.082347Z","shell.execute_reply.started":"2024-05-19T00:34:42.562784Z","shell.execute_reply":"2024-05-19T00:34:56.081028Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import os,math,sys,torch,re,numpy as np\nfrom types import SimpleNamespace as ns\nfrom collections import namedtuple","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:34:56.084437Z","iopub.execute_input":"2024-05-19T00:34:56.084758Z","iopub.status.idle":"2024-05-19T00:34:59.293516Z","shell.execute_reply.started":"2024-05-19T00:34:56.084725Z","shell.execute_reply":"2024-05-19T00:34:59.292696Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"dim3 = namedtuple('dim3', ['x','y','z'], defaults=(1,1))","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:34:59.294547Z","iopub.execute_input":"2024-05-19T00:34:59.294899Z","iopub.status.idle":"2024-05-19T00:34:59.299713Z","shell.execute_reply.started":"2024-05-19T00:34:59.294875Z","shell.execute_reply":"2024-05-19T00:34:59.298714Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"d = dim3(2,3)\nd","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:34:59.301702Z","iopub.execute_input":"2024-05-19T00:34:59.301979Z","iopub.status.idle":"2024-05-19T00:34:59.316208Z","shell.execute_reply.started":"2024-05-19T00:34:59.301954Z","shell.execute_reply":"2024-05-19T00:34:59.315420Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"dim3(x=2, y=3, z=1)"},"metadata":{}}]},{"cell_type":"code","source":"d.x,d.y","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:34:59.317347Z","iopub.execute_input":"2024-05-19T00:34:59.317705Z","iopub.status.idle":"2024-05-19T00:34:59.328194Z","shell.execute_reply.started":"2024-05-19T00:34:59.317673Z","shell.execute_reply":"2024-05-19T00:34:59.327269Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(2, 3)"},"metadata":{}}]},{"cell_type":"code","source":"np.set_printoptions(precision=2, linewidth=140)\ntorch.set_printoptions(precision=2, linewidth=140, sci_mode=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:34:59.329222Z","iopub.execute_input":"2024-05-19T00:34:59.329549Z","iopub.status.idle":"2024-05-19T00:34:59.336364Z","shell.execute_reply.started":"2024-05-19T00:34:59.329523Z","shell.execute_reply":"2024-05-19T00:34:59.335529Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"sys.path.insert(0, '..')","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:34:59.337589Z","iopub.execute_input":"2024-05-19T00:34:59.338081Z","iopub.status.idle":"2024-05-19T00:34:59.346216Z","shell.execute_reply.started":"2024-05-19T00:34:59.338056Z","shell.execute_reply":"2024-05-19T00:34:59.345544Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from torch.utils.cpp_extension import load_inline\n%load_ext wurlitzer\n\ndef show_image(x, figsize=(4,3), **kwargs):\n    plt.figure(figsize=figsize)\n    plt.axis('off')\n    if len(x.shape) == 3: x = x.permute(1,2,0)\n    plt.imshow(x.cpu(), **kwargs)\n\n\ncuda_begin = r\"\"\"\n#include <torch/extension.h>\n#include <stdio.h>\n#include <c10/cuda/CUDAException.h>\n\n#define CHECK_CUDA(x) TORCH_CHECK(x.device().is_cuda(), #x \" must be a CUDA Tensor\")\n#define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.device().is_contiguous(), #x \" must be a CONTIGUOUS\")\n#define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x);\n\ninline unsigned int cdiv(unsigned int a, unsigned int b) { return (a + b - 1) / b;}\n\"\"\"\n\ndef clear_cudafiles(path_str):\n  \"\"\"Clears the files alone in pwd\"\"\"\n  objs = os.listdir(path_str)\n  for obj in objs:\n    if os.path.isfile(os.path.join(path_str, obj)):\n      os.remove(os.path.join(path_str, obj))\n  print(\"Files deleted. Refresh...\")\n\ndef load_cuda(cuda_src, cpp_src, funcs, opt=False, verbose=False,\n    build_directory='.'):\n    clear_cudafiles(build_directory)\n    return load_inline(cuda_sources=[cuda_src],\n                        cpp_sources=[cpp_src],\n                        functions=funcs,\n                        extra_cuda_cflags=[\"-O2 -std=c++20\"],\n                        verbose=True,\n                        name=\"inline_ext\",\n                        build_directory=build_directory)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T01:07:35.452305Z","iopub.execute_input":"2024-05-19T01:07:35.452711Z","iopub.status.idle":"2024-05-19T01:07:35.468179Z","shell.execute_reply.started":"2024-05-19T01:07:35.452679Z","shell.execute_reply":"2024-05-19T01:07:35.467254Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"The wurlitzer extension is already loaded. To reload it, use:\n  %reload_ext wurlitzer\n","output_type":"stream"}]},{"cell_type":"code","source":"from math import ceil\n\ndef cdiv(a, b):\n    return ceil(a + b - 1 / b)\n\ncdiv(5, 10)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:47:24.407753Z","iopub.execute_input":"2024-05-19T00:47:24.408465Z","iopub.status.idle":"2024-05-19T00:47:24.417499Z","shell.execute_reply.started":"2024-05-19T00:47:24.408428Z","shell.execute_reply":"2024-05-19T00:47:24.416387Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"15"},"metadata":{}}]},{"cell_type":"code","source":"# os.environ['CUDA_LAUNCH_BLOCKING']='1'\ntorch.manual_seed(42);","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:37:20.791693Z","iopub.execute_input":"2024-05-19T00:37:20.792447Z","iopub.status.idle":"2024-05-19T00:37:20.799686Z","shell.execute_reply.started":"2024-05-19T00:37:20.792414Z","shell.execute_reply":"2024-05-19T00:37:20.798849Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"m1 = torch.rand(5120, 256)\nm1s = m1[:4]\nm2 = torch.rand(256,5120)\nm2s = m2[:,:4]","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:37:25.501413Z","iopub.execute_input":"2024-05-19T00:37:25.502092Z","iopub.status.idle":"2024-05-19T00:37:25.557520Z","shell.execute_reply.started":"2024-05-19T00:37:25.502060Z","shell.execute_reply":"2024-05-19T00:37:25.556737Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Reminder","metadata":{}},{"cell_type":"markdown","source":"### 2d Python kernel","metadata":{}},{"cell_type":"code","source":"def blk_kernel2d(f, blocks, threads, *args):\n    for i0 in range(blocks.y):\n        for i1 in range(blocks.x):\n            for j0 in range(threads.y):\n                for j1 in range(threads.x): f(dim3(i1,i0), dim3(j1,j0), threads, *args)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def matmul_bk(blockIdx, threadIdx, blockDim, m, n, out, h, w, k):\n    r = blockIdx.y*blockDim.y + threadIdx.y\n    c = blockIdx.x*blockDim.x + threadIdx.x\n    \n    if (r>=h or c>=w): return\n    o = 0.\n    for i in range(k): o += m[r*k+i] * n[i*w+c]\n    out[r*w+c] = o","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def matmul_2d(m, n):\n    h,k  = m.shape\n    k2,w = n.shape\n    assert k==k2, \"Size mismatch!\"\n    output = torch.zeros(h, w, dtype=m.dtype)\n    tpb = dim3(16,16)\n    blocks = dim3(cdiv(w,tpb.x), cdiv(h,tpb.y))\n    blk_kernel2d(matmul_bk, blocks, tpb,\n                 m.flatten(), n.flatten(), output.flatten(), h, w, k)\n    return output","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.isclose(matmul_2d(m1s, m2s), m1s@m2s).all()","metadata":{},"execution_count":null,"outputs":[{"execution_count":null,"output_type":"execute_result","data":{"text/plain":["tensor(True)"]},"metadata":{}}]},{"cell_type":"markdown","source":"### CUDA","metadata":{}},{"cell_type":"code","source":"cuda_src = cuda_begin + r'''\n__global__ void matmul_k(float* m, float* n, float* out, int h, int w, int k) {\n    int r = blockIdx.y*blockDim.y + threadIdx.y;\n    int c = blockIdx.x*blockDim.x + threadIdx.x;\n\n    if (r>=h || c>=w) return;\n    float o = 0;\n    for (int i = 0; i<k; ++i) o += m[r*k+i] * n[i*w+c];\n    out[r*w+c] = o;\n}\n\ntorch::Tensor matmul(torch::Tensor m, torch::Tensor n) {\n    // CHECK_INPUT(m); CHECK_INPUT(n);\n    int h = m.size(0);\n    int w = n.size(1);\n    int k = m.size(1);\n    TORCH_CHECK(k==n.size(0), \"Size mismatch!\");\n    auto output = torch::zeros({h, w}, m.options());\n\n    dim3 tpb(16,16);\n    dim3 blocks(cdiv(w, tpb.x), cdiv(h, tpb.y));\n    matmul_k<<<blocks, tpb>>>(\n        m.data_ptr<float>(), n.data_ptr<float>(), output.data_ptr<float>(), h, w, k);\n    C10_CUDA_KERNEL_LAUNCH_CHECK();\n    return output;\n}\n'''","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:38:38.686775Z","iopub.execute_input":"2024-05-19T00:38:38.687442Z","iopub.status.idle":"2024-05-19T00:38:38.693998Z","shell.execute_reply.started":"2024-05-19T00:38:38.687406Z","shell.execute_reply":"2024-05-19T00:38:38.693094Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"fname = 'matmul'","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:38:42.436619Z","iopub.execute_input":"2024-05-19T00:38:42.437457Z","iopub.status.idle":"2024-05-19T00:38:42.442999Z","shell.execute_reply.started":"2024-05-19T00:38:42.437423Z","shell.execute_reply":"2024-05-19T00:38:42.441912Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def get_sig(fname, src):\n    res = re.findall(rf'^(.+\\s+{fname}\\(.*?\\))\\s*{{?\\s*$', src, re.MULTILINE)\n    return res[0]+';' if res else None","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:38:45.746517Z","iopub.execute_input":"2024-05-19T00:38:45.747465Z","iopub.status.idle":"2024-05-19T00:38:45.753253Z","shell.execute_reply.started":"2024-05-19T00:38:45.747432Z","shell.execute_reply":"2024-05-19T00:38:45.752400Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"cpp_src = get_sig(fname, cuda_src)\ncpp_src","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:38:48.086900Z","iopub.execute_input":"2024-05-19T00:38:48.087287Z","iopub.status.idle":"2024-05-19T00:38:48.095323Z","shell.execute_reply.started":"2024-05-19T00:38:48.087255Z","shell.execute_reply":"2024-05-19T00:38:48.094325Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"'torch::Tensor matmul(torch::Tensor m, torch::Tensor n);'"},"metadata":{}}]},{"cell_type":"code","source":"module = load_cuda(cuda_src, cpp_src, [fname])","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:40:34.852105Z","iopub.execute_input":"2024-05-19T00:40:34.852490Z","iopub.status.idle":"2024-05-19T00:41:49.377873Z","shell.execute_reply.started":"2024-05-19T00:40:34.852459Z","shell.execute_reply":"2024-05-19T00:41:49.376916Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Files deleted. Refresh...\n","output_type":"stream"},{"name":"stderr","text":"Detected CUDA files, patching ldflags\nEmitting ninja build file ./build.ninja...\nBuilding extension module inline_ext...\nAllowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\nLoading extension module inline_ext...\n","output_type":"stream"}]},{"cell_type":"code","source":"m1c,m2c = m1.contiguous().cuda(),m2.contiguous().cuda()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:41:49.379501Z","iopub.execute_input":"2024-05-19T00:41:49.379787Z","iopub.status.idle":"2024-05-19T00:41:49.516864Z","shell.execute_reply.started":"2024-05-19T00:41:49.379762Z","shell.execute_reply":"2024-05-19T00:41:49.515864Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"module.matmul(m1c,m2c).shape","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:41:49.517919Z","iopub.execute_input":"2024-05-19T00:41:49.518192Z","iopub.status.idle":"2024-05-19T00:41:49.550905Z","shell.execute_reply.started":"2024-05-19T00:41:49.518168Z","shell.execute_reply":"2024-05-19T00:41:49.550136Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"torch.Size([5120, 5120])"},"metadata":{}}]},{"cell_type":"code","source":"torch.isclose(module.matmul(m1c,m2c), m1c@m2c).all()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:41:49.552868Z","iopub.execute_input":"2024-05-19T00:41:49.553147Z","iopub.status.idle":"2024-05-19T00:41:49.777380Z","shell.execute_reply.started":"2024-05-19T00:41:49.553122Z","shell.execute_reply":"2024-05-19T00:41:49.776453Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"tensor(True, device='cuda:0')"},"metadata":{}}]},{"cell_type":"code","source":"%%timeit -n 100\nmodule.matmul(m1c,m2c)\ntorch.cuda.synchronize()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:42:31.987308Z","iopub.execute_input":"2024-05-19T00:42:31.987719Z","iopub.status.idle":"2024-05-19T00:42:55.134704Z","shell.execute_reply.started":"2024-05-19T00:42:31.987690Z","shell.execute_reply":"2024-05-19T00:42:55.133698Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"33.1 ms ± 35.6 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"When I removed the call to the kernel itself, it took around 50 µs (0.05 ms) to run, so that's the overhead of the call on my machine.","metadata":{}},{"cell_type":"markdown","source":"## Shared mem","metadata":{}},{"cell_type":"markdown","source":"### Python","metadata":{}},{"cell_type":"code","source":"a = torch.zeros(5)\nb,c = a[:3],a[3:]","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:41:52.100475Z","iopub.execute_input":"2024-05-19T00:41:52.101163Z","iopub.status.idle":"2024-05-19T00:41:52.107087Z","shell.execute_reply.started":"2024-05-19T00:41:52.101127Z","shell.execute_reply":"2024-05-19T00:41:52.106223Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"b[1] = 2\nc[0] = 6\na","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:41:52.108090Z","iopub.execute_input":"2024-05-19T00:41:52.108327Z","iopub.status.idle":"2024-05-19T00:41:52.143590Z","shell.execute_reply.started":"2024-05-19T00:41:52.108306Z","shell.execute_reply":"2024-05-19T00:41:52.142776Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"tensor([0., 2., 0., 6., 0.])"},"metadata":{}}]},{"cell_type":"code","source":"def blk_kernel2d_shar(f, blocks, threads, sh_sz, *args, **kwargs):\n    for i0 in range(blocks.y):\n        for i1 in range(blocks.x):\n            shared = torch.zeros(sh_sz)  # will create 0s of size 512 for example\n            f(dim3(i1,i0), threads, shared, *args, **kwargs)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:42:55.136482Z","iopub.execute_input":"2024-05-19T00:42:55.136785Z","iopub.status.idle":"2024-05-19T00:42:55.144085Z","shell.execute_reply.started":"2024-05-19T00:42:55.136759Z","shell.execute_reply":"2024-05-19T00:42:55.143084Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def matmul_tiled_bk(blockIdx, blockDim, shared, m, n, out, h, w, k, tw):\n    shar_sz = tw*tw\n    ms,ns = shared[:shar_sz],shared[shar_sz:]  # this will split shar_sz into two\n\n    for ph in range(cdiv(k,tw)):\n        idx = ph*tw\n        # fill shared\n        for tr in range(blockDim.y):\n            for tc in range(blockDim.x):\n                r,c = blockIdx.y*blockDim.y + tr, blockIdx.x*blockDim.x + tc\n                ms[tr*tw+tc] = m[ tc+idx + r*k] if r<h and idx+tc<k else 0. # filling zeros if above h\n                ns[tr*tw+tc] = n[(tr+idx)*w +c] if c<w and idx+tr<k else 0. # filling zeros if above w\n\n        # do dotprods from shared\n        for tr in range(blockDim.y):\n            for tc in range(blockDim.x):\n                r,c = blockIdx.y*blockDim.y + tr, blockIdx.x*blockDim.x + tc\n                for i in range(tw):\n                    if r*w+c<len(out): out[r*w+c] += ms[tr*tw+i] * ns[tw*i+tc]","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:50:39.752266Z","iopub.execute_input":"2024-05-19T00:50:39.753162Z","iopub.status.idle":"2024-05-19T00:50:39.763426Z","shell.execute_reply.started":"2024-05-19T00:50:39.753128Z","shell.execute_reply":"2024-05-19T00:50:39.762452Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def matmul_2d(m, n, tw=16):\n    h,k  = m.shape\n    k2,w = n.shape\n    assert k==k2, \"Size mismatch!\"\n    output = torch.zeros(h, w, dtype=m.dtype)\n    tpb = dim3(tw,tw)\n    blocks = dim3(cdiv(w,tpb.x), cdiv(h,tpb.y))\n    # share size is 16 * 16 * 2 = 512\n    blk_kernel2d_shar(matmul_tiled_bk, blocks, tpb, tw*tw*2,\n                      m.flatten(), n.flatten(), output.flatten(),\n                      h, w, k, tw=tw)\n    return output","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:50:42.422188Z","iopub.execute_input":"2024-05-19T00:50:42.422574Z","iopub.status.idle":"2024-05-19T00:50:42.430566Z","shell.execute_reply.started":"2024-05-19T00:50:42.422543Z","shell.execute_reply":"2024-05-19T00:50:42.429792Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"m1s.shape, m2.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:50:47.227310Z","iopub.execute_input":"2024-05-19T00:50:47.228148Z","iopub.status.idle":"2024-05-19T00:50:47.234882Z","shell.execute_reply.started":"2024-05-19T00:50:47.228118Z","shell.execute_reply":"2024-05-19T00:50:47.233997Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"(torch.Size([4, 256]), torch.Size([256, 5120]))"},"metadata":{}}]},{"cell_type":"code","source":"torch.isclose(matmul_2d(m1s, m2s, tw=16), m1s@m2s).all()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:51:11.297258Z","iopub.execute_input":"2024-05-19T00:51:11.298121Z","iopub.status.idle":"2024-05-19T00:55:17.337069Z","shell.execute_reply.started":"2024-05-19T00:51:11.298088Z","shell.execute_reply":"2024-05-19T00:55:17.335657Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":38,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[38;5;241m.\u001b[39misclose(\u001b[43mmatmul_2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm1s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm2s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m, m1s\u001b[38;5;129m@m2s\u001b[39m)\u001b[38;5;241m.\u001b[39mall()\n","Cell \u001b[0;32mIn[36], line 8\u001b[0m, in \u001b[0;36mmatmul_2d\u001b[0;34m(m, n, tw)\u001b[0m\n\u001b[1;32m      6\u001b[0m tpb \u001b[38;5;241m=\u001b[39m dim3(tw,tw)\n\u001b[1;32m      7\u001b[0m blocks \u001b[38;5;241m=\u001b[39m dim3(cdiv(w,tpb\u001b[38;5;241m.\u001b[39mx), cdiv(h,tpb\u001b[38;5;241m.\u001b[39my))\n\u001b[0;32m----> 8\u001b[0m \u001b[43mblk_kernel2d_shar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatmul_tiled_bk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtpb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtw\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtw\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n","Cell \u001b[0;32mIn[30], line 5\u001b[0m, in \u001b[0;36mblk_kernel2d_shar\u001b[0;34m(f, blocks, threads, sh_sz, *args, **kwargs)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i1 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(blocks\u001b[38;5;241m.\u001b[39mx):\n\u001b[1;32m      4\u001b[0m     shared \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(sh_sz)\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[35], line 19\u001b[0m, in \u001b[0;36mmatmul_tiled_bk\u001b[0;34m(blockIdx, blockDim, shared, m, n, out, h, w, k, tw)\u001b[0m\n\u001b[1;32m     17\u001b[0m r,c \u001b[38;5;241m=\u001b[39m blockIdx\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m*\u001b[39mblockDim\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m+\u001b[39m tr, blockIdx\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m*\u001b[39mblockDim\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m+\u001b[39m tc\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(tw):\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m*\u001b[39mw\u001b[38;5;241m+\u001b[39mc\u001b[38;5;241m<\u001b[39m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m: out[r\u001b[38;5;241m*\u001b[39mw\u001b[38;5;241m+\u001b[39mc] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ms[tr\u001b[38;5;241m*\u001b[39mtw\u001b[38;5;241m+\u001b[39mi] \u001b[38;5;241m*\u001b[39m ns[tw\u001b[38;5;241m*\u001b[39mi\u001b[38;5;241m+\u001b[39mtc]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:964\u001b[0m, in \u001b[0;36mTensor.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;21m__neg__\u001b[39m \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39m_TensorBase\u001b[38;5;241m.\u001b[39mneg\n\u001b[1;32m    962\u001b[0m \u001b[38;5;21m__abs__\u001b[39m \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39m_TensorBase\u001b[38;5;241m.\u001b[39mabs\n\u001b[0;32m--> 964\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    966\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__len__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"### Python run_threads","metadata":{}},{"cell_type":"code","source":"def run_threads(f, blockDim, *args, **kwargs):\n    for i0 in range(blockDim.y):\n        for i1 in range(blockDim.x): f(i0, i1, *args, **kwargs)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:55:46.147879Z","iopub.execute_input":"2024-05-19T00:55:46.148476Z","iopub.status.idle":"2024-05-19T00:55:46.154586Z","shell.execute_reply.started":"2024-05-19T00:55:46.148442Z","shell.execute_reply":"2024-05-19T00:55:46.153648Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"def matmul_tiled_bk(blockIdx, blockDim, shared, m, n, out, h, w, k, tw):\n    shar_sz = tw*tw\n    ms,ns = shared[:shar_sz],shared[shar_sz:]\n\n    def get_rc(tr, tc): return blockIdx.y*blockDim.y + tr, blockIdx.x*blockDim.x + tc\n\n    def fill_shared_tk(tr, tc, ph):\n        r,c = get_rc(tr, tc)\n        ms[tr*tw+tc] = m[ tc + ph*tw + r*k] if r<h and (ph*tw+tc)<k else 0.\n        ns[tr*tw+tc] = n[(tr + ph*tw)*w +c] if c<w and (ph*tw+tr)<k else 0.\n\n    def dotprod_tk(tr, tc):\n        r,c = get_rc(tr, tc)\n        for i in range(tw):\n            if r*w+c<len(out): out[r*w+c] += ms[tr*tw+i] * ns[tw*i+tc]\n\n    for ph in range(int(math.ceil(k/tw))):\n        run_threads(fill_shared_tk, blockDim, ph)\n        run_threads(dotprod_tk, blockDim)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:55:47.672484Z","iopub.execute_input":"2024-05-19T00:55:47.673358Z","iopub.status.idle":"2024-05-19T00:55:47.683574Z","shell.execute_reply.started":"2024-05-19T00:55:47.673326Z","shell.execute_reply":"2024-05-19T00:55:47.682518Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"def matmul_2d(m, n, tw=16):\n    h,k  = m.shape\n    k2,w = n.shape\n    assert k==k2, \"Size mismatch!\"\n    output = torch.zeros(h, w, dtype=m.dtype)\n    tpb = dim3(tw,tw)\n    blocks = dim3(cdiv(w,tpb.x), cdiv(h,tpb.y))\n    blk_kernel2d_shar(matmul_tiled_bk, blocks, tpb, tw*tw*2,\n                      m.flatten(), n.flatten(), output.flatten(),\n                      h, w, k, tw=tw)\n    return output","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:55:51.562403Z","iopub.execute_input":"2024-05-19T00:55:51.562790Z","iopub.status.idle":"2024-05-19T00:55:51.570493Z","shell.execute_reply.started":"2024-05-19T00:55:51.562760Z","shell.execute_reply":"2024-05-19T00:55:51.569582Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"m1s.shape, m2s.shape","metadata":{},"execution_count":null,"outputs":[{"execution_count":null,"output_type":"execute_result","data":{"text/plain":["(torch.Size([4, 256]), torch.Size([256, 4]))"]},"metadata":{}}]},{"cell_type":"code","source":"torch.isclose(matmul_2d(m1s, m2s, tw=16), m1s@m2s).all()","metadata":{},"execution_count":null,"outputs":[{"execution_count":null,"output_type":"execute_result","data":{"text/plain":["tensor(True)"]},"metadata":{}}]},{"cell_type":"markdown","source":"### Python threads","metadata":{}},{"cell_type":"code","source":"import threading\nfrom threading import Barrier, Thread\nfrom concurrent.futures import ThreadPoolExecutor\n# need to understand how threading works, and see it in action","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:56:04.317752Z","iopub.execute_input":"2024-05-19T00:56:04.318646Z","iopub.status.idle":"2024-05-19T00:56:04.324025Z","shell.execute_reply.started":"2024-05-19T00:56:04.318609Z","shell.execute_reply":"2024-05-19T00:56:04.323114Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"def g(x, sb):\n    print(x)\n    sb.wait()\n    print(-x)\n    sb.wait()\n    print(x*10)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:56:07.532458Z","iopub.execute_input":"2024-05-19T00:56:07.532826Z","iopub.status.idle":"2024-05-19T00:56:07.539102Z","shell.execute_reply.started":"2024-05-19T00:56:07.532798Z","shell.execute_reply":"2024-05-19T00:56:07.538155Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"num = 3\nsb = Barrier(num)\nwith ThreadPoolExecutor(num) as ex:\n    list(ex.map(lambda i: g(i,sb), range(1,num+1)))","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:56:15.333870Z","iopub.execute_input":"2024-05-19T00:56:15.334247Z","iopub.status.idle":"2024-05-19T00:56:15.342930Z","shell.execute_reply.started":"2024-05-19T00:56:15.334217Z","shell.execute_reply":"2024-05-19T00:56:15.342013Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"1\n2\n3\n-3\n-1\n-2\n30\n20\n10\n","output_type":"stream"}]},{"cell_type":"code","source":"def blk_kernel2d_shar(f, blocks, tpb, sh_sz, *args, **kwargs):\n    for i0 in range(blocks.y):\n        for i1 in range(blocks.x):\n            shar = torch.zeros(sh_sz)\n            syncb = Barrier(tpb.y*tpb.x)\n            threads = [Thread(target=f, args=(dim3(i1,i0), dim3(p,o), tpb, shar, syncb, *args), kwargs=kwargs)\n                       for o in range(tpb.y) for p in range(tpb.x)]\n            for tr in threads: tr.start()\n            for tr in threads: tr.join()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:58:05.703067Z","iopub.execute_input":"2024-05-19T00:58:05.703517Z","iopub.status.idle":"2024-05-19T00:58:05.712382Z","shell.execute_reply.started":"2024-05-19T00:58:05.703483Z","shell.execute_reply":"2024-05-19T00:58:05.711437Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"def matmul_tiled_bk(blockIdx, threadIdx, blockDim, shared, syncb, m, n, out, h, w, k, tw):\n    tc,tr = threadIdx.x,threadIdx.y\n    r = blockIdx.y*blockDim.y + tr\n    c = blockIdx.x*blockDim.x + tc\n\n    shar_sz = tw*tw\n    ms,ns = shared[:shar_sz],shared[shar_sz:]\n\n    p = 0.\n    for ph in range(cdiv(k,tw)):\n        ms[tr*tw+tc] = m[ tc + ph*tw + r*k] if r<h and (ph*tw+tc)<k else 0.\n        ns[tr*tw+tc] = n[(tr + ph*tw)*w +c] if c<w and (ph*tw+tr)<k else 0.\n        syncb.wait()\n        for i in range(tw): p += ms[tr*tw+i] * ns[tw*i+tc]\n        syncb.wait()\n\n    if (r<h and c<w): out[r*w + c] = p","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:58:08.997357Z","iopub.execute_input":"2024-05-19T00:58:08.997749Z","iopub.status.idle":"2024-05-19T00:58:09.007849Z","shell.execute_reply.started":"2024-05-19T00:58:08.997717Z","shell.execute_reply":"2024-05-19T00:58:09.006950Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"def matmul_2d(m, n, tw=16):\n    h,k  = m.shape\n    k2,w = n.shape\n    assert k==k2, \"Size mismatch!\"\n    output = torch.zeros(h, w, dtype=m.dtype)\n    tpb = dim3(tw,tw)\n    blocks = dim3(cdiv(w,tpb.x), cdiv(h,tpb.y))\n    blk_kernel2d_shar(matmul_tiled_bk, blocks, tpb, tw*tw*2,\n                      m.flatten(), n.flatten(), output.flatten(),\n                      h, w, k, tw=tw)\n    return output","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:58:13.052406Z","iopub.execute_input":"2024-05-19T00:58:13.052796Z","iopub.status.idle":"2024-05-19T00:58:13.060843Z","shell.execute_reply.started":"2024-05-19T00:58:13.052764Z","shell.execute_reply":"2024-05-19T00:58:13.059861Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"torch.isclose(matmul_2d(m1s, m2s, tw=8), m1s@m2s).all()","metadata":{},"execution_count":null,"outputs":[{"execution_count":null,"output_type":"execute_result","data":{"text/plain":["tensor(True)"]},"metadata":{}}]},{"cell_type":"markdown","source":"### CUDA dynamic shared","metadata":{}},{"cell_type":"markdown","source":"Code auto-generated by ChatGPT 4, using the following prompt:\n\n> Convert the following python code to CUDA C, keeping formatting and variable names the same where possible. You can remove `blockIdx, threadIdx, blockDim, shared` from the argument list, since they're already provided by CUDA. Change `syncb.wait()` to `__syncthreads`. Use `extern __shared__ float shared[]` to create the `shared` array. Use the C ternary operator to replace the Python equivalent where appropriate. If the Python code uses any non-standard functions, you can assume the same functions are also available to the translated C code with the same name and signature.\n\nThe generated code worked first time, although we did some minor cleanups afterwards (e.g. renaming `shared` to `ms`).","metadata":{}},{"cell_type":"code","source":"cuda_src = cuda_begin + r'''\n__global__ void matmul_k(float *m, float *n, float *out, int h, int w, int k, int tw) {\n    int tc=threadIdx.x, tr=threadIdx.y;\n    int r=blockIdx.y*blockDim.y+tr;\n    int c=blockIdx.x*blockDim.x+tc;\n\n    extern __shared__ float ms[];\n    float *ns = &ms[tw*tw];  // allocates ns from where ms ends\n\n    float p = 0.0f;\n    for (int ph = 0; ph < cdiv(k,tw); ++ph) {\n        int idx = ph*tw;\n        ms[tr*tw + tc] = r<h && idx+tc<k ? m[ tc+idx + r*k ] : 0.0f;\n        ns[tr*tw + tc] = c<w && idx+tr<k ? n[(tr+idx)*w + c] : 0.0f;\n        __syncthreads();\n        for (int i=0; i<tw; ++i) p += ms[tr*tw + i] * ns[tw*i + tc]; // this is the operation\n        __syncthreads();\n    }\n    if (r<h && c<w) out[r*w + c] = p;\n}\n'''","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:59:37.842122Z","iopub.execute_input":"2024-05-19T00:59:37.842924Z","iopub.status.idle":"2024-05-19T00:59:37.848705Z","shell.execute_reply.started":"2024-05-19T00:59:37.842891Z","shell.execute_reply":"2024-05-19T00:59:37.847850Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"cuda_src += r'''\ntorch::Tensor matmul_dyn(torch::Tensor m, torch::Tensor n) {\n    // CHECK_INPUT(m); CHECK_INPUT(n);\n    int h=m.size(0), w=n.size(1), k=m.size(1);\n    // TORCH_CHECK(k==n.size(0), \"Size mismatch!\");\n    auto output = torch::zeros({h, w}, m.options());\n\n    /*\n    // Commented out section demonstrating basic idea of dynamic size calculation\n    cudaDeviceProp devProp;\n    CUDA_ERR(cudaGetDeviceProperties(&devProp, 0));\n    int maxThreads = devProp.maxThreadsPerBlock;\n    size_t requiredSize = static_cast<size_t>(maxThreads) * 2 * sizeof(float);\n    size_t size = min(devProp.sharedMemPerBlock, requiredSize);\n    int TW = std::sqrt(maxThreads);\n    */\n\n    // We just set size fixed for now\n    int TW = 16;\n    size_t size = TW*TW * 2 * sizeof(float);\n    dim3 tpb(TW,TW);\n    dim3 blocks(cdiv(w, tpb.x), cdiv(h, tpb.y));\n    matmul_k<<<blocks,tpb,size>>>(\n        m.data_ptr<float>(), n.data_ptr<float>(), output.data_ptr<float>(), h, w, k, TW);\n    C10_CUDA_KERNEL_LAUNCH_CHECK();\n    return output;\n}\n'''","metadata":{"execution":{"iopub.status.busy":"2024-05-19T01:06:34.102394Z","iopub.execute_input":"2024-05-19T01:06:34.102757Z","iopub.status.idle":"2024-05-19T01:06:34.109419Z","shell.execute_reply.started":"2024-05-19T01:06:34.102728Z","shell.execute_reply":"2024-05-19T01:06:34.108577Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"fname = 'matmul_dyn'","metadata":{"execution":{"iopub.status.busy":"2024-05-19T01:00:19.006420Z","iopub.execute_input":"2024-05-19T01:00:19.007066Z","iopub.status.idle":"2024-05-19T01:00:19.012440Z","shell.execute_reply.started":"2024-05-19T01:00:19.007034Z","shell.execute_reply":"2024-05-19T01:00:19.011531Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"cpp_src = get_sig(fname, cuda_src)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T01:00:21.586659Z","iopub.execute_input":"2024-05-19T01:00:21.587562Z","iopub.status.idle":"2024-05-19T01:00:21.593317Z","shell.execute_reply.started":"2024-05-19T01:00:21.587521Z","shell.execute_reply":"2024-05-19T01:00:21.592361Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"cpp_src","metadata":{"execution":{"iopub.status.busy":"2024-05-19T01:11:03.922367Z","iopub.execute_input":"2024-05-19T01:11:03.923224Z","iopub.status.idle":"2024-05-19T01:11:03.929684Z","shell.execute_reply.started":"2024-05-19T01:11:03.923193Z","shell.execute_reply":"2024-05-19T01:11:03.928893Z"},"trusted":true},"execution_count":61,"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"'torch::Tensor matmul_dyn(torch::Tensor m, torch::Tensor n);'"},"metadata":{}}]},{"cell_type":"code","source":"module = load_cuda(cuda_src, cpp_src, [fname], opt=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T01:09:43.242206Z","iopub.execute_input":"2024-05-19T01:09:43.242841Z","iopub.status.idle":"2024-05-19T01:09:43.352429Z","shell.execute_reply.started":"2024-05-19T01:09:43.242805Z","shell.execute_reply":"2024-05-19T01:09:43.351193Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"Files deleted. Refresh...\n","output_type":"stream"},{"name":"stderr","text":"No modifications detected for re-loaded extension module inline_ext_v3, skipping build step...\nLoading extension module inline_ext_v3...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mload_cuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcuda_src\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcpp_src\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[56], line 34\u001b[0m, in \u001b[0;36mload_cuda\u001b[0;34m(cuda_src, cpp_src, funcs, opt, verbose, build_directory)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_cuda\u001b[39m(cuda_src, cpp_src, funcs, opt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     32\u001b[0m     build_directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     33\u001b[0m     clear_cudafiles(build_directory)\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_inline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcuda_sources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcuda_src\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mcpp_sources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcpp_src\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuncs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-O2 -std=c++20\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minline_ext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuild_directory\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1635\u001b[0m, in \u001b[0;36mload_inline\u001b[0;34m(name, cpp_sources, cuda_sources, functions, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, with_pytorch_error_handling, keep_intermediates, use_pch)\u001b[0m\n\u001b[1;32m   1631\u001b[0m     _maybe_write(cuda_source_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(cuda_sources))\n\u001b[1;32m   1633\u001b[0m     sources\u001b[38;5;241m.\u001b[39mappend(cuda_source_path)\n\u001b[0;32m-> 1635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_jit_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1637\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_ldflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_include_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_python_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_standalone\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_intermediates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_intermediates\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1736\u001b[0m, in \u001b[0;36m_jit_compile\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_standalone:\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _get_exec_path(name, build_directory)\n\u001b[0;32m-> 1736\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_import_module_from_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_python_module\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/cpp_extension.py:2136\u001b[0m, in \u001b[0;36m_import_module_from_library\u001b[0;34m(module_name, path, is_python_module)\u001b[0m\n\u001b[1;32m   2134\u001b[0m spec \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mspec_from_file_location(module_name, filepath)\n\u001b[1;32m   2135\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2136\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule_from_spec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2137\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(spec\u001b[38;5;241m.\u001b[39mloader, importlib\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mLoader)\n\u001b[1;32m   2138\u001b[0m spec\u001b[38;5;241m.\u001b[39mloader\u001b[38;5;241m.\u001b[39mexec_module(module)\n","File \u001b[0;32m<frozen importlib._bootstrap>:571\u001b[0m, in \u001b[0;36mmodule_from_spec\u001b[0;34m(spec)\u001b[0m\n","File \u001b[0;32m<frozen importlib._bootstrap_external>:1176\u001b[0m, in \u001b[0;36mcreate_module\u001b[0;34m(self, spec)\u001b[0m\n","File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: /kaggle/working/./inline_ext_v3.so: cannot open shared object file: No such file or directory"],"ename":"ImportError","evalue":"/kaggle/working/./inline_ext_v3.so: cannot open shared object file: No such file or directory","output_type":"error"}]},{"cell_type":"code","source":"torch.isclose(module.matmul_dyn(m1c,m2c), m1c@m2c).all()","metadata":{},"execution_count":null,"outputs":[{"execution_count":null,"output_type":"execute_result","data":{"text/plain":["tensor(True, device='cuda:0')"]},"metadata":{}}]},{"cell_type":"code","source":"%%timeit -n 10\nmodule.matmul_dyn(m1c,m2c)\ntorch.cuda.synchronize()","metadata":{},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":"6.64 ms ± 319 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"}]},{"cell_type":"markdown","source":"### CUDA static shared","metadata":{}},{"cell_type":"code","source":"cuda_src = cuda_begin + r'''\nconstexpr int tw = 16;\n\n__global__ void matmul_ks(float *m, float *n, float *out, int h, int w, int k) {\n    __shared__ float ms[tw][tw], ns[tw][tw];\n    int tc=threadIdx.x, tr=threadIdx.y;\n    int r=blockIdx.y*blockDim.y+tr, c=blockIdx.x*blockDim.x+tc;\n\n    float p=0.0f;\n    for (int ph=0; ph < cdiv(k,tw); ++ph) {\n        int idx = ph*tw;\n        ms[tr][tc] = r<h && idx+tc<k ? m[ tc+idx + r*k ] : 0.0f;\n        ns[tr][tc] = c<w && idx+tr<k ? n[(tr+idx)*w + c] : 0.0f;\n        __syncthreads();\n        for (int i=0; i<tw; ++i) p += ms[tr][i] * ns[i][tc];\n        __syncthreads();\n    }\n    if (r<h && c<w) out[r*w + c] = p;\n}\n\ntorch::Tensor matmul_static(torch::Tensor m, torch::Tensor n) {\n    CHECK_INPUT(m); CHECK_INPUT(n);\n    int h=m.size(0), w=n.size(1), k=m.size(1);\n    TORCH_CHECK(k==n.size(0), \"Size mismatch!\");\n    auto output = torch::zeros({h, w}, m.options());\n    dim3 tpb(tw,tw);\n    dim3 blocks(cdiv(w, tpb.x), cdiv(h, tpb.y));\n    matmul_ks<<<blocks,tpb>>>(m.data_ptr<float>(), n.data_ptr<float>(), output.data_ptr<float>(), h, w, k);\n    C10_CUDA_KERNEL_LAUNCH_CHECK();\n    return output;\n}\n'''","metadata":{"execution":{"iopub.status.busy":"2024-05-19T01:12:05.062081Z","iopub.execute_input":"2024-05-19T01:12:05.062491Z","iopub.status.idle":"2024-05-19T01:12:05.069284Z","shell.execute_reply.started":"2024-05-19T01:12:05.062452Z","shell.execute_reply":"2024-05-19T01:12:05.068359Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"fname = 'matmul_static'\ncpp_src = get_sig(fname, cuda_src)\nmodule = load_cuda(cuda_src, cpp_src, [fname])\ntorch.isclose(module.matmul_static(m1c,m2c), m1c@m2c).all()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T01:12:10.661700Z","iopub.execute_input":"2024-05-19T01:12:10.662673Z","iopub.status.idle":"2024-05-19T01:12:30.130603Z","shell.execute_reply.started":"2024-05-19T01:12:10.662633Z","shell.execute_reply":"2024-05-19T01:12:30.129141Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"Files deleted. Refresh...\n","output_type":"stream"},{"name":"stderr","text":"The input conditions for extension module inline_ext have changed. Bumping to version 4 and re-building as inline_ext_v4...\nDetected CUDA files, patching ldflags\nEmitting ninja build file ./build.ninja...\nBuilding extension module inline_ext_v4...\nAllowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/cpp_extension.py:2100\u001b[0m, in \u001b[0;36m_run_ninja_build\u001b[0;34m(build_directory, verbose, error_prefix)\u001b[0m\n\u001b[1;32m   2099\u001b[0m     stdout_fileno \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 2100\u001b[0m     \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstdout_fileno\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTDOUT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2106\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2107\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2108\u001b[0m     \u001b[38;5;66;03m# Python 2 and 3 compatible way of getting the error object.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/subprocess.py:526\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[0;32m--> 526\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m    527\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n","\u001b[0;31mCalledProcessError\u001b[0m: Command '['ninja', '-v']' returned non-zero exit status 1.","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[63], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m fname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatmul_static\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m cpp_src \u001b[38;5;241m=\u001b[39m get_sig(fname, cuda_src)\n\u001b[0;32m----> 3\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mload_cuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcuda_src\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcpp_src\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m torch\u001b[38;5;241m.\u001b[39misclose(module\u001b[38;5;241m.\u001b[39mmatmul_static(m1c,m2c), m1c\u001b[38;5;129m@m2c\u001b[39m)\u001b[38;5;241m.\u001b[39mall()\n","Cell \u001b[0;32mIn[56], line 34\u001b[0m, in \u001b[0;36mload_cuda\u001b[0;34m(cuda_src, cpp_src, funcs, opt, verbose, build_directory)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_cuda\u001b[39m(cuda_src, cpp_src, funcs, opt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     32\u001b[0m     build_directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     33\u001b[0m     clear_cudafiles(build_directory)\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_inline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcuda_sources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcuda_src\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mcpp_sources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcpp_src\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuncs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-O2 -std=c++20\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minline_ext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuild_directory\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1635\u001b[0m, in \u001b[0;36mload_inline\u001b[0;34m(name, cpp_sources, cuda_sources, functions, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, with_pytorch_error_handling, keep_intermediates, use_pch)\u001b[0m\n\u001b[1;32m   1631\u001b[0m     _maybe_write(cuda_source_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(cuda_sources))\n\u001b[1;32m   1633\u001b[0m     sources\u001b[38;5;241m.\u001b[39mappend(cuda_source_path)\n\u001b[0;32m-> 1635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_jit_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1637\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_ldflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_include_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_python_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_standalone\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_intermediates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_intermediates\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1710\u001b[0m, in \u001b[0;36m_jit_compile\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1706\u001b[0m                 hipified_sources\u001b[38;5;241m.\u001b[39madd(hipify_result[s_abs]\u001b[38;5;241m.\u001b[39mhipified_path \u001b[38;5;28;01mif\u001b[39;00m s_abs \u001b[38;5;129;01min\u001b[39;00m hipify_result \u001b[38;5;28;01melse\u001b[39;00m s_abs)\n\u001b[1;32m   1708\u001b[0m             sources \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(hipified_sources)\n\u001b[0;32m-> 1710\u001b[0m         \u001b[43m_write_ninja_file_and_build_library\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m            \u001b[49m\u001b[43msources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_cflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_ldflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_ldflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1716\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_include_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_include_paths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1717\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1718\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1719\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_cuda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1720\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_standalone\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_standalone\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1721\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1722\u001b[0m     baton\u001b[38;5;241m.\u001b[39mrelease()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1823\u001b[0m, in \u001b[0;36m_write_ninja_file_and_build_library\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_standalone)\u001b[0m\n\u001b[1;32m   1821\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m   1822\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBuilding extension module \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m-> 1823\u001b[0m \u001b[43m_run_ninja_build\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1824\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1825\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1826\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mError building extension \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/cpp_extension.py:2116\u001b[0m, in \u001b[0;36m_run_ninja_build\u001b[0;34m(build_directory, verbose, error_prefix)\u001b[0m\n\u001b[1;32m   2114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(error, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m error\u001b[38;5;241m.\u001b[39moutput:  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m   2115\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;241m*\u001b[39mSUBPROCESS_DECODE_ARGS)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m-> 2116\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n","\u001b[0;31mRuntimeError\u001b[0m: Error building extension 'inline_ext_v4'"],"ename":"RuntimeError","evalue":"Error building extension 'inline_ext_v4'","output_type":"error"}]},{"cell_type":"code","source":"%%timeit -n 10\nmodule.matmul_static(m1c,m2c)\ntorch.cuda.synchronize()","metadata":{},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":"4.34 ms ± 11.5 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"}]},{"cell_type":"markdown","source":"## Numba","metadata":{}},{"cell_type":"code","source":"from numba import cuda\nfrom numba.cuda import as_cuda_array as ca","metadata":{"execution":{"iopub.status.busy":"2024-05-19T01:12:59.171742Z","iopub.execute_input":"2024-05-19T01:12:59.172115Z","iopub.status.idle":"2024-05-19T01:12:59.755879Z","shell.execute_reply.started":"2024-05-19T01:12:59.172086Z","shell.execute_reply":"2024-05-19T01:12:59.754894Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"@cuda.jit\ndef matmul_k_numba(m, n, out, tw):\n    cbi,cbd,tid = cuda.blockIdx,cuda.blockDim,cuda.threadIdx\n    tc,tr = tid.x,tid.y\n    r,c = cbi.y * cbd.y + tr, cbi.x * cbd.x + tc\n    h,k  = m.shape\n    k2,w = n.shape\n\n    shar = cuda.shared.array(0, dtype=np.float32)\n    ms,ns = shar[:tw*tw],shar[tw*tw:2*tw*tw]\n\n    p = np.float32(0.0)\n    for ph in range(math.ceil(k/tw)):\n        idx = ph*tw\n        ms[tr*tw+tc] = m[r, tc+idx] if r<h and idx+tc<k else 0.\n        ns[tr*tw+tc] = n[tr+idx, c] if c<w and idx+tr<k else 0.\n        cuda.syncthreads()\n        for i in range(tw): p += ms[tr*tw+i] * ns[i*tw+tc]\n        cuda.syncthreads()\n    if r < h and c < w: out[r, c] = p","metadata":{"execution":{"iopub.status.busy":"2024-05-19T01:13:04.296466Z","iopub.execute_input":"2024-05-19T01:13:04.297216Z","iopub.status.idle":"2024-05-19T01:13:04.307695Z","shell.execute_reply.started":"2024-05-19T01:13:04.297182Z","shell.execute_reply":"2024-05-19T01:13:04.306784Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"def matmul_2d_numba(m, n, tw=16):\n    h,k  = m.shape\n    k2,w = n.shape\n    assert k==k2, \"Size mismatch!\"\n    out = torch.zeros(h, w, dtype=m.dtype, device=m.device)\n    dyn_shared_mem_size = 2 * tw * tw * 4\n    tpb = tw,tw\n    blocks = cdiv(w,tpb[0]), cdiv(h,tpb[1])\n    matmul_k_numba[blocks, tpb, 0, dyn_shared_mem_size](ca(m), ca(n), ca(out), tw) \n    return out","metadata":{"execution":{"iopub.status.busy":"2024-05-19T01:13:22.897191Z","iopub.execute_input":"2024-05-19T01:13:22.898086Z","iopub.status.idle":"2024-05-19T01:13:22.905839Z","shell.execute_reply.started":"2024-05-19T01:13:22.898044Z","shell.execute_reply":"2024-05-19T01:13:22.904953Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"torch.isclose(matmul_2d_numba(m1c,m2c), m1c@m2c).all()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T01:13:27.596989Z","iopub.execute_input":"2024-05-19T01:13:27.597365Z","iopub.status.idle":"2024-05-19T01:13:45.003817Z","shell.execute_reply.started":"2024-05-19T01:13:27.597335Z","shell.execute_reply":"2024-05-19T01:13:45.002830Z"},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"tensor(True, device='cuda:0')"},"metadata":{}}]},{"cell_type":"code","source":"%%timeit -n 10\nmatmul_2d_numba(m1c,m2c)\ntorch.cuda.synchronize()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T01:13:48.326532Z","iopub.execute_input":"2024-05-19T01:13:48.327219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Extra: Optimised Dynamic CUDA with Template","metadata":{}},{"cell_type":"code","source":"cuda_src = cuda_begin + r'''\ntemplate<int tw>\n__global__ void matmul_k(float *m, float *n, float *out, int h, int w, int k) {\n    int tc=threadIdx.x, tr=threadIdx.y;\n    int r=blockIdx.y*blockDim.y+tr, c=blockIdx.x*blockDim.x+tc;\n    extern __shared__ float ms[];\n    float *ns = &ms[tw*tw];\n\n    float p = 0.0f;\n    for (int ph = 0; ph < cdiv(k,tw); ++ph) {\n        int idx = ph*tw;\n        ms[tr*tw + tc] = r<h && idx+tc<k ? m[ tc+idx + r*k ] : 0.0f;\n        ns[tr*tw + tc] = c<w && idx+tr<k ? n[(tr+idx)*w + c] : 0.0f;\n        __syncthreads();\n        for (int i=0; i<tw; ++i) p += ms[tr*tw + i] * ns[tw*i + tc];\n        __syncthreads();\n    }\n    if (r<h && c<w) out[r*w + c] = p;\n}\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cuda_src += r'''\ntorch::Tensor matmul_dyn1(torch::Tensor m, torch::Tensor n) {\n    // CHECK_INPUT(m); CHECK_INPUT(n);\n    int h=m.size(0), w=n.size(1), k=m.size(1);\n    TORCH_CHECK(k==n.size(0), \"Size mismatch!\");\n    auto output = torch::zeros({h, w}, m.options());\n    int TW = 16; // TODO: Calculate this dynamically\n    size_t size = TW*TW*2 * sizeof(float) + 1;\n    dim3 tpb(TW,TW);\n    dim3 blocks(cdiv(w, tpb.x), cdiv(h, tpb.y));\n\n    auto f = [&](auto kf) { kf<<<blocks, tpb, size>>>(\n        m.data_ptr<float>(), n.data_ptr<float>(), output.data_ptr<float>(), h, w, k);\n    };\n    switch(TW) {\n        case 8: f(matmul_k<8>); break;\n        case 16: f(matmul_k<16>); break;\n        case 32: f(matmul_k<32>); break;\n        default: break;\n    }\n    C10_CUDA_KERNEL_LAUNCH_CHECK();\n    return output;\n}\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfname = 'matmul_dyn1'\ncpp_src = get_sig(fname, cuda_src)\nmodule = load_cuda(cuda_src, cpp_src, [fname], opt=True)\nfunc = getattr(module, fname)","metadata":{},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":"CPU times: user 93.2 ms, sys: 37.3 ms, total: 130 ms\n\nWall time: 43.7 s\n"}]},{"cell_type":"code","source":"torch.isclose(func(m1c,m2c), m1c@m2c).all()","metadata":{},"execution_count":null,"outputs":[{"execution_count":null,"output_type":"execute_result","data":{"text/plain":["tensor(True, device='cuda:0')"]},"metadata":{}}]},{"cell_type":"code","source":"%%timeit -n 10\nfunc(m1c,m2c)\ntorch.cuda.synchronize()","metadata":{},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":"4.35 ms ± 13.6 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}