{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook illustrates how the datapipes work, along the Transforms in TorchText\n",
    "\n",
    "In addition, the T5 and XLMR model loading, and training process is also included. \n",
    "\n",
    "Due to the issue with getting the data using torchtext.datasets, tried manually \n",
    "creating the datapipes. Even in that, there are errors cropping up. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchdata.datapipes as dp\n",
    "import torchtext.transforms as T\n",
    "import spacy\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "eng = spacy.load(\"en_core_web_md\") # Load the English model to tokenize English text\n",
    "de = spacy.load(\"de_core_news_md\") # Load the German model to tokenize German text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = 'data/deu.txt'\n",
    "data_pipe = dp.iter.IterableWrapper([FILE_PATH])  # note the file_path is a list\n",
    "data_pipe = dp.iter.FileOpener(data_pipe, mode='rb')\n",
    "data_pipe = data_pipe.parse_csv(skip_lines=0,\n",
    "                                delimiter='\\t',\n",
    "                                as_tuple=True)\n",
    "# Process of opening the file is different than the usual case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Go.', 'Geh.')\n"
     ]
    }
   ],
   "source": [
    "for sample in data_pipe:\n",
    "    print(sample)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data_pipe)[799:850]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeAttribution(row):\n",
    "    \"\"\"\n",
    "    Function to keep the first two elements in a tuple\n",
    "    \"\"\"\n",
    "    return row[:2]\n",
    "data_pipe = data_pipe.map(removeAttribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(eng.tokenizer('This is a test case'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "is\n",
      "a\n",
      "test\n",
      "case\n"
     ]
    }
   ],
   "source": [
    "for x in eng.tokenizer('This is a test case'):\n",
    "    print(x.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engTokenize(text):\n",
    "    \"\"\"\n",
    "    Tokenize an English text and return a list of tokens\n",
    "    If tokenizer is called directly, the list is not returned\n",
    "    \"\"\"\n",
    "    return [token.text for token in eng.tokenizer(text)]\n",
    "\n",
    "def deTokenize(text):\n",
    "    \"\"\"\n",
    "    Tokenize a German text and return a list of tokens\n",
    "    \"\"\"\n",
    "    return [token.text for token in de.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Have', 'a', 'good', 'day', '!', '!', '!']\n",
      "['Haben', 'Sie', 'einen', 'guten', 'Tag', '!', '!', '!']\n"
     ]
    }
   ],
   "source": [
    "print(engTokenize(\"Have a good day!!!\"))\n",
    "print(deTokenize(\"Haben Sie einen guten Tag!!!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTokens(data_iter, place):\n",
    "    \"\"\"\n",
    "    Function to yield tokens from an iterator. Since, our iterator contains\n",
    "    tuple of sentences (source and target), `place` parameters defines for which\n",
    "    index to return the tokens for. `place=0` for source and `place=1` for target\n",
    "    \"\"\"\n",
    "    for english, german in data_iter:\n",
    "        if place == 0:\n",
    "            yield engTokenize(english)\n",
    "        else:\n",
    "            yield deTokenize(german)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sos: for start of sentence\n",
    "\n",
    "- eos: for end of sentence\n",
    "\n",
    "- unk: for unknown words. An example of unknown word is the one skipped because of min_freq=2.\n",
    "\n",
    "- pad: is the padding token. While training, a model we mostly train in batches. In a batch, there can be sentences of different length. So, we pad the shorter sentences with <pad> token to make length of all sequences in the batch equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_vocab = build_vocab_from_iterator(\n",
    "    getTokens(data_pipe,0),\n",
    "    min_freq=2,\n",
    "    specials= ['<pad>', '<sos>', '<eos>', '<unk>'],\n",
    "    special_first=True\n",
    ")\n",
    "source_vocab.set_default_index(source_vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At line 5, we set special_first=True. Which means <pad> will get index 0, <sos> index 1, <eos> index 2, and <unk> will get index 3 in the vocabulary.\n",
    "\n",
    "At line 7, we set default index as index of <unk>. That means if some word is not in vocabulary, we will use <unk> instead of that unknown word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vocab = build_vocab_from_iterator(\n",
    "    getTokens(data_pipe,1),\n",
    "    min_freq=2,\n",
    "    specials= ['<pad>', '<sos>', '<eos>', '<unk>'],\n",
    "    special_first=True\n",
    ")\n",
    "target_vocab.set_default_index(target_vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>', '<sos>', '<eos>', '<unk>', '.', 'I', 'Tom', 'to', 'you']\n",
      "['<pad>', '<sos>', '<eos>', '<unk>', '.', ',', 'Tom', 'Ich', '?']\n"
     ]
    }
   ],
   "source": [
    "print(source_vocab.get_itos()[:9])\n",
    "print(target_vocab.get_itos()[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.VocabTransform(vocab=source_vocab)(['wipes', '<sos>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTransform(vocab):\n",
    "    \"\"\"\n",
    "    Create transforms based on given vocabulary. The returned transform is applied to sequence\n",
    "    of tokens.\n",
    "    \"\"\"\n",
    "    text_tranform = T.Sequential(\n",
    "        ## converts the sentences to indices based on given vocabulary\n",
    "        T.VocabTransform(vocab=vocab),\n",
    "        ## Add <sos> at beginning of each sentence. \n",
    "        # 1 because the index for <sos> in vocabulary is\n",
    "        T.AddToken(1, begin=True),\n",
    "        ## Add <eos> at beginning of each sentence.\n",
    "        # 2 because the index for <eos> in vocabulary is\n",
    "        T.AddToken(2, begin=False)\n",
    "    )\n",
    "    return text_tranform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some sentence=I fainted.\n"
     ]
    }
   ],
   "source": [
    "temp_list = list(data_pipe)\n",
    "some_sentence = temp_list[799][0]\n",
    "print(\"Some sentence=\", end=\"\")\n",
    "print(some_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed sentence=[1, 5, 2897, 4, 2]\n"
     ]
    }
   ],
   "source": [
    "# getTransform function is not required, a simple declaiton of transform will be \n",
    "# sufficient\n",
    "transformed_sentence = getTransform(source_vocab)(engTokenize(some_sentence))\n",
    "print(\"Transformed sentence=\", end=\"\")\n",
    "print(transformed_sentence)  # Transformed sentence=[1, 5, 2897, 4, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> I fainted . <eos> "
     ]
    }
   ],
   "source": [
    "index_to_string = source_vocab.get_itos()\n",
    "for index in transformed_sentence:\n",
    "    print(index_to_string[index], end=\" \")  # <sos> I fainted . <eos> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1, 616, 4, 2], [1, 739, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "def applyTransform(sequence_pair):\n",
    "    \"\"\"\n",
    "    Apply transforms to sequence of tokens in a sequence pair\n",
    "    \"\"\"\n",
    "\n",
    "    return (\n",
    "        getTransform(source_vocab)(engTokenize(sequence_pair[0])),\n",
    "        getTransform(target_vocab)(deTokenize(sequence_pair[1]))\n",
    "    )\n",
    "data_pipe = data_pipe.map(applyTransform) ## Apply the function to each element in the iterator\n",
    "temp_list = list(data_pipe)\n",
    "print(temp_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortBucket(bucket):\n",
    "    \"\"\"\n",
    "    Function to sort a given bucket. Here, we want to sort based on the length of\n",
    "    source and target sequence.\n",
    "    \"\"\"\n",
    "    return sorted(bucket, key=lambda x: (len(x[0]), len(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pipe = data_pipe.bucketbatch(\n",
    "    batch_size = 4, batch_num=5,  bucket_num=1,\n",
    "    use_in_batch_shuffle=False, sort_key=sortBucket\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep batch size = 4.\n",
    "\n",
    "batch_num is the number of batches to keep in a bucket\n",
    "\n",
    "bucket_num is the number of buckets to keep in a pool for shuffling\n",
    "\n",
    "sort_key specifies the function that takes a bucket and sorts it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(([1, 5, 964, 4, 2], [1, 5, 258, 4, 2], [1, 5, 360, 4, 2], [1, 5335, 21, 4, 2]), ([1, 7, 22, 1475, 4, 2], [1, 7, 22, 376, 4, 2], [1, 297, 10, 19, 561, 4, 2], [1, 896, 32, 21, 33, 1133, 24, 2]))\n"
     ]
    }
   ],
   "source": [
    "def separateSourceTarget(sequence_pairs):\n",
    "    \"\"\"\n",
    "    input of form: `[(X_1,y_1), (X_2,y_2), (X_3,y_3), (X_4,y_4)]`\n",
    "    output of form: `((X_1,X_2,X_3,X_4), (y_1,y_2,y_3,y_4))`\n",
    "    \"\"\"\n",
    "    sources,targets = zip(*sequence_pairs)\n",
    "    return sources,targets\n",
    "\n",
    "## Apply the function to each element in the iterator\n",
    "data_pipe = data_pipe.map(separateSourceTarget)\n",
    "print(list(data_pipe)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyPadding(pair_of_sequences):\n",
    "    \"\"\"\n",
    "    Convert sequences to tensors and apply padding\n",
    "    \"\"\"\n",
    "    return (T.ToTensor(0)(list(pair_of_sequences[0])), T.ToTensor(0)(list(pair_of_sequences[1])))\n",
    "## `T.ToTensor(0)` returns a transform that converts the sequence to `torch.tensor` and also applies\n",
    "# padding. Here, `0` is passed to the constructor to specify the index of the `<pad>` token in the\n",
    "# vocabulary.\n",
    "data_pipe = data_pipe.map(applyPadding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:  <sos> <unk> . <eos> <pad>\n",
      "Traget:  <sos> Fang an . <eos>\n",
      "Source:  <sos> Do it . <eos>\n",
      "Traget:  <sos> Mache es ! <eos>\n",
      "Source:  <sos> Do it . <eos>\n",
      "Traget:  <sos> Tue es . <eos>\n",
      "Source:  <sos> Go on . <eos>\n",
      "Traget:  <sos> Mach weiter . <eos>\n"
     ]
    }
   ],
   "source": [
    "source_index_to_string = source_vocab.get_itos()\n",
    "target_index_to_string = target_vocab.get_itos()\n",
    "\n",
    "def showSomeTransformedSentences(data_pipe):\n",
    "    \"\"\"\n",
    "    Function to show how the sentences look like after applying all transforms.\n",
    "    Here we try to print actual words instead of corresponding index\n",
    "    \"\"\"\n",
    "    for sources,targets in data_pipe:\n",
    "        if sources[0][-1] != 0:\n",
    "            continue # Just to visualize padding of shorter sentences\n",
    "        for i in range(4):\n",
    "            source = \"\"\n",
    "            for token in sources[i]:\n",
    "                source += \" \" + source_index_to_string[token]\n",
    "            target = \"\"\n",
    "            for token in targets[i]:\n",
    "                target += \" \" + target_index_to_string[token]\n",
    "            print(f\"Source: {source}\")\n",
    "            print(f\"Traget: {target}\")\n",
    "        break\n",
    "\n",
    "showSomeTransformedSentences(data_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['▁This', '▁is', '▁a', '▁sentence', '▁piece']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlmr_spm_model_path = r\"https://download.pytorch.org/models/text/xlmr.sentencepiece.bpe.model\"\n",
    "spt = T.SentencePieceTokenizer(sp_model_path=xlmr_spm_model_path)\n",
    "spt(['This is a sentence piece'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the GPT-2 data, we have to access OpenAI public server & then extract the info. \n",
    "https://github.com/openai/gpt-2/blob/master/download_model.py\n",
    "The public domain seems to be taken offline, so planning to explore how Transformers library will help\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "transformer_gpt2_tokeniser = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_path = \"/home/kamal/.cache/huggingface/hub/models--gpt2/snapshots/11c5a3d5811f50298f278a704980280950aedb10/vocab.json\"\n",
    "encoder_path = \"/home/kamal/.cache/huggingface/hub/models--gpt2/snapshots/11c5a3d5811f50298f278a704980280950aedb10/tokenizer.json\"\n",
    "\n",
    "gpt_bpe = T.GPT2BPETokenizer(encoder_json_path=encoder_path,\n",
    "                             vocab_bpe_path=vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 525k/525k [00:01<00:00, 459kB/s] \n",
      "100%|██████████| 862k/862k [00:01<00:00, 527kB/s]  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['988',\n",
       " '269',\n",
       " '3240',\n",
       " '537',\n",
       " '1982',\n",
       " '269',\n",
       " '5916',\n",
       " '631',\n",
       " '1265',\n",
       " '1070',\n",
       " '3044',\n",
       " '531',\n",
       " '518',\n",
       " '1002']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merges_file = \"http://download.pytorch.org/models/text/clip_merges.bpe\"\n",
    "encoder_file = \"http://download.pytorch.org/models/text/clip_encoder.json\"\n",
    "# https://github.com/mlfoundations/open_clip/blob/main/src/clip/tokenizer.py\n",
    "clip_token = T.CLIPTokenizer(merges_path=merges_file,\n",
    "                             encoder_json_path=encoder_file)\n",
    "clip_token(\"Ms.Fox and Mr.Wolf are being very kind to the world \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on WordPiece algorithm introduced in paper: https://static.googleusercontent.com/media/research.google.com/ja//pubs/archive/37842.pdf\n",
    "\n",
    "The backend kernel implementation is taken and modified from https://github.com/LieluoboAi/radish.\n",
    "\n",
    "See PR https://github.com/pytorch/text/pull/1707 summary for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232k/232k [00:00<00:00, 439kB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['there',\n",
       " 'is',\n",
       " 'always',\n",
       " 'something',\n",
       " 'good',\n",
       " 'happening',\n",
       " ',',\n",
       " 'for',\n",
       " 'you',\n",
       " 'to',\n",
       " 'cher',\n",
       " '##ish']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_bert = \"https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt\"\n",
    "bert_tokeniser = T.BERTTokenizer(vocab_path=vocab_bert, do_lower_case=True,\n",
    "                                 return_tokens=True)\n",
    "bert_tokeniser(\"There is always something good happening, for you to cherish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232k/232k [00:00<00:00, 521kB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2045',\n",
       " '2003',\n",
       " '2467',\n",
       " '2242',\n",
       " '2204',\n",
       " '6230',\n",
       " '1010',\n",
       " '2005',\n",
       " '2017',\n",
       " '2000',\n",
       " '24188',\n",
       " '4509']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokeniser = T.BERTTokenizer(vocab_path=vocab_bert,\n",
    "                                 do_lower_case=True, return_tokens=False)\n",
    "bert_tokeniser(\"There is always something good happening, for you to cherish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2045', '2003', '2012', '19738', '3367', '2028', '2204', '2589']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncate = T.Truncate(max_seq_len=8)\n",
    "tokened = truncate(bert_tokeniser(\"there is atleast one good done for a million bad deeds\"))\n",
    "tokened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Error: \n",
    "\n",
    "ValueError: too many dimensions 'str'\n",
    "\n",
    "https://stackoverflow.com/questions/65804689/with-bert-text-classification-valueerror-too-many-dimensions-str-error-occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m add_1 \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mAddToken(\u001b[38;5;241m1\u001b[39m, begin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m add_tokened \u001b[38;5;241m=\u001b[39m add_1(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokened\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      3\u001b[0m add_tokened\n",
      "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"
     ]
    }
   ],
   "source": [
    "add_1 = T.AddToken(1, begin=True)\n",
    "add_tokened = add_1(torch.tensor(tokened))\n",
    "add_tokened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m pad_1 \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mPadTransform(max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, pad_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m pad_1(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokened\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"
     ]
    }
   ],
   "source": [
    "pad_1 = T.PadTransform(max_length=10, pad_value=1)\n",
    "pad_1(torch.tensor(tokened))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import (\n",
    "    Multi30k,\n",
    "    DBpedia,\n",
    "    CC100,\n",
    "    SST2,\n",
    "    IMDB,\n",
    "    AG_NEWS,\n",
    "    CoLA,\n",
    "    SQuAD2,\n",
    "    PennTreebank,\n",
    "    CNNDM,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ag_news = AG_NEWS(split=('train'))\n",
    "list(ag_news)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_dm = CNNDM(split='val')\n",
    "list(cnn_dm)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working on Further Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build text pre-processing pipeline for XLM-R model\n",
    "\n",
    "read SST-2 dataset and transform it using text and label transformation\n",
    "\n",
    "instantiate classification model using pre-trained XLM-R encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_pipe = SST2(split='train')\n",
    "test_pipe = SST2(split='dev')\n",
    "sst2_path_train = '/media/kamal/DATA/torch/text/datasets/SST2/SST-2/train.tsv'\n",
    "sst2_path_test = '/media/kamal/DATA/torch/text/datasets/SST2/SST-2/test.tsv'\n",
    "sst2_path_dev = '/media/kamal/DATA/torch/text/datasets/SST2/SST-2/dev.tsv'\n",
    "# dev_pipe = SST2(split='dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(test_pipe)  # lists all the data\n",
    "list(train_pipe)  # lists all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('hide new secretions from the parental units', 0)\n",
      "('contains no wit , only labored gags', 0)\n",
      "('that loves its characters and communicates something rather beautiful about human nature', 1)\n",
      "('remains utterly satisfied to remain the same throughout', 0)\n",
      "('on the worst revenge-of-the-nerds clichés the filmmakers could dredge up', 0)\n",
      "(\"that 's far too tragic to merit such superficial treatment\", 0)\n",
      "('demonstrates that the director of such hollywood blockbusters as patriot games can still turn out a small , personal film with an emotional wallop .', 1)\n"
     ]
    }
   ],
   "source": [
    "for ind, x in enumerate(train_pipe):\n",
    "    print(x)\n",
    "    if ind > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.hub import load_state_dict_from_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_idx = 1\n",
    "bos_idx = 0  # begin of sentence\n",
    "eos_idx = 2\n",
    "max_seq_len = 256\n",
    "xlmr_vocab_path = r\"https://download.pytorch.org/models/text/xlmr.vocab.pt\"\n",
    "xlmr_spm_model_path = r\"https://download.pytorch.org/models/text/xlmr.sentencepiece.bpe.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torchtext.transforms as T\n",
    "\n",
    "text_transform = T.Sequential(\n",
    "    T.SentencePieceTokenizer(xlmr_spm_model_path),\n",
    "    T.VocabTransform(load_state_dict_from_url(xlmr_vocab_path)),\n",
    "    T.Truncate(max_seq_len - 2),\n",
    "    T.AddToken(token=bos_idx, begin=True),\n",
    "    T.AddToken(token=eos_idx, begin=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Sequential.forward() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtext_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mThis seems to be a correct example\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: Sequential.forward() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "text_transform('This seems to be a correct example', '5')  # providing the additional variable raises the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyTransform(x):\n",
    "    return [text_transform(x[0]), x[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_pipe = train_pipe.map(applyTransform)\n",
    "t_pipe = t_pipe.batch(batch_size)\n",
    "t_pipe = t_pipe.rows2columnar(['token_ids','target'])\n",
    "t_loader = DataLoader(t_pipe, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kamal/.local/lib/python3.11/site-packages/torch/utils/data/datapipes/iter/combining.py:333: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
      "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(t_loader))['target']  # [0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_pipe = test_pipe.map(applyTransform)\n",
    "d_pipe = d_pipe.batch(batch_size)\n",
    "d_pipe = d_pipe.rows2columnar(['token_ids','target'])\n",
    "d_loader = DataLoader(d_pipe, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kamal/.local/lib/python3.11/site-packages/torch/utils/data/datapipes/iter/combining.py:333: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
      "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(d_loader))['target']  # [0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.models import RobertaClassificationHead, XLMR_BASE_ENCODER\n",
    "import torch\n",
    "\n",
    "num_classes = 2\n",
    "input_dim = 768\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "\n",
    "classifier_head = RobertaClassificationHead(num_classes=num_classes,\n",
    "                                            input_dim=input_dim)\n",
    "model = XLMR_BASE_ENCODER.get_model(head=classifier_head,)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaClassificationHead(\n",
      "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (activation_fn): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(classifier_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaBundle(_encoder_conf=RobertaEncoderConf(vocab_size=250002, embedding_dim=768, ffn_dimension=3072, padding_idx=1, max_seq_len=514, num_attention_heads=12, num_encoder_layers=12, dropout=0.1, scaling=None, normalize_before=False), _path='https://download.pytorch.org/models/text/xlmr.base.encoder.pt', _head=None, transform=<function <lambda> at 0x7f2e200e4f40>)\n"
     ]
    }
   ],
   "source": [
    "print(XLMR_BASE_ENCODER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RobertaModel(\n",
    "  (encoder): RobertaEncoder(\n",
    "    (transformer): TransformerEncoder(\n",
    "      (token_embedding): Embedding(250002, 768, padding_idx=1)\n",
    "      (layers): TransformerEncoder(\n",
    "        (layers): ModuleList(\n",
    "          (0-11): 12 x TransformerEncoderLayer(\n",
    "            (self_attn): MultiheadAttention(\n",
    "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
    "            )\n",
    "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
    "            (dropout): Dropout(p=0.1, inplace=False)\n",
    "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
    "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
    "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
    "            (dropout1): Dropout(p=0.1, inplace=False)\n",
    "            (dropout2): Dropout(p=0.1, inplace=False)\n",
    "          )\n",
    "        )\n",
    "      )\n",
    "      (positional_embedding): PositionalEmbedding(\n",
    "        (embedding): Embedding(514, 768, padding_idx=1)\n",
    "      )\n",
    "      (embedding_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
    "      (dropout): Dropout(p=0.1, inplace=False)\n",
    "    )\n",
    "  )\n",
    "  (head): RobertaClassificationHead(\n",
    "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "    (dropout): Dropout(p=0.1, inplace=False)\n",
    "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
    "    (activation_fn): ReLU()\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch import nn \n",
    "\n",
    "learning_rate = 1e-5\n",
    "optim = AdamW(model.parameters(), lr=learning_rate)\n",
    "criteria = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def train_step(input, target):\n",
    "    output = model(input)\n",
    "    loss = criteria(output, target)\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "\n",
    "def eval_step(input, target):\n",
    "    output = model(input)\n",
    "    loss = criteria(output, target).item()\n",
    "    return float(loss), (output.argmax(1) == target).type(torch.float).sum().item()\n",
    "\n",
    "\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    counter = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in d_loader:\n",
    "            input = F.to_tensor(batch[\"token_ids\"], padding_value=padding_idx).to(device)\n",
    "            target = torch.tensor(batch[\"target\"]).to(device)\n",
    "            loss, predictions = eval_step(input, target)\n",
    "            total_loss += loss\n",
    "            correct_predictions += predictions\n",
    "            total_predictions += len(target)\n",
    "            counter += 1\n",
    "\n",
    "    return total_loss / counter, correct_predictions / total_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    for batch in t_loader:\n",
    "        # print(batch)\n",
    "        input = F.to_tensor(batch[\"token_ids\"], padding_value=padding_idx).to(device)\n",
    "        target = torch.tensor(batch[\"target\"]).to(device)\n",
    "        train_step(input, target)\n",
    "\n",
    "    loss, accuracy = evaluate()\n",
    "    print(\"Epoch = [{}], loss = [{}], accuracy = [{}]\".format(e, loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tarfile\n",
    "\n",
    "class TgzDataset(Dataset):\n",
    "    def __init__(self, tgz_file):\n",
    "        self.tgz_file = tgz_file\n",
    "        self.samples = []\n",
    "        with tarfile.open(tgz_file, \"r:gz\") as f:\n",
    "            for member in f.members:\n",
    "                self.samples.append(member.name)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with tarfile.open(self.tgz_file, \"r:gz\") as f:\n",
    "            with f.extractfile(self.samples[idx]) as f:\n",
    "                sample = f.read()\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_path = '/home/kamal/.cache/torch/text/datasets/cnn_stories.tgz'\n",
    "\n",
    "cnn_tgz = TgzDataset(tgz_file=cnn_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "# Create a tarfile.open object\n",
    "tar = tarfile.open(cnn_path)\n",
    "\n",
    "# Extract the contents of the .tgz file to a directory\n",
    "tar.extractall()\n",
    "\n",
    "# Close the tarfile.open object\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "cnn_stories = glob.glob(\"cnn/stories/*.stories\")\n",
    "cnn_dataPipe = dp.iter.IterableWrapper(cnn_stories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this step, not much progress... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 792k/792k [00:01<00:00, 522kB/s] \n"
     ]
    }
   ],
   "source": [
    "from torchtext.models import T5Transform\n",
    "\n",
    "padding_idx = 0\n",
    "eos_idx = 1\n",
    "max_seq_len = 512\n",
    "t5_sp_model_path = \"https://download.pytorch.org/models/text/t5_tokenizer_base.model\"\n",
    "\n",
    "transform = T5Transform(\n",
    "    sp_model_path=t5_sp_model_path,\n",
    "    max_seq_len=max_seq_len,\n",
    "    eos_idx=eos_idx,\n",
    "    padding_idx=padding_idx,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.models import T5_BASE_GENERATION\n",
    "\n",
    "\n",
    "t5_base = T5_BASE_GENERATION\n",
    "transform = t5_base.transform()\n",
    "model = t5_base.get_model()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "``` T5Model(\n",
    "  (token_embeddings): Embedding(32128, 768, padding_idx=0)\n",
    "  (encoder): T5Encoder(\n",
    "    (token_embeddings): Embedding(32128, 768, padding_idx=0)\n",
    "    (layers): ModuleList(\n",
    "      (0): T5Layer(\n",
    "        (self_attn): T5MultiheadAttention(\n",
    "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
    "          (relative_attention_bias): Embedding(32, 12)\n",
    "        )\n",
    "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
    "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
    "        (norm1): T5LayerNorm()\n",
    "        (norm2): T5LayerNorm()\n",
    "        (dropout1): Dropout(p=0.0, inplace=False)\n",
    "        (dropout2): Dropout(p=0.0, inplace=False)\n",
    "        (dropout3): Dropout(p=0.0, inplace=False)\n",
    "      )\n",
    "      (1-11): 11 x T5Layer(\n",
    "        (self_attn): T5MultiheadAttention(\n",
    "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
    "        )\n",
    "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
    "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
    "        (norm1): T5LayerNorm()\n",
    "        (norm2): T5LayerNorm()\n",
    "        (dropout1): Dropout(p=0.0, inplace=False)\n",
    "        (dropout2): Dropout(p=0.0, inplace=False)\n",
    "        (dropout3): Dropout(p=0.0, inplace=False)\n",
    "      )\n",
    "    )\n",
    "    (norm): T5LayerNorm()\n",
    "    (dropout1): Dropout(p=0.0, inplace=False)\n",
    "    (dropout2): Dropout(p=0.0, inplace=False)\n",
    "  )\n",
    "  (decoder): T5Decoder(\n",
    "    (layers): ModuleList(\n",
    "      (0): T5Layer(\n",
    "        (self_attn): T5MultiheadAttention(\n",
    "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
    "          (relative_attention_bias): Embedding(32, 12)\n",
    "        )\n",
    "        (cross_attn): T5MultiheadAttention(\n",
    "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
    "        )\n",
    "        (norm3): T5LayerNorm()\n",
    "        (dropout4): Dropout(p=0.0, inplace=False)\n",
    "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
    "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
    "        (norm1): T5LayerNorm()\n",
    "        (norm2): T5LayerNorm()\n",
    "        (dropout1): Dropout(p=0.0, inplace=False)\n",
    "        (dropout2): Dropout(p=0.0, inplace=False)\n",
    "        (dropout3): Dropout(p=0.0, inplace=False)\n",
    "      )\n",
    "      (1-11): 11 x T5Layer(\n",
    "        (self_attn): T5MultiheadAttention(\n",
    "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
    "        )\n",
    "        (cross_attn): T5MultiheadAttention(\n",
    "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
    "        )\n",
    "        (norm3): T5LayerNorm()\n",
    "        (dropout4): Dropout(p=0.0, inplace=False)\n",
    "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
    "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
    "        (norm1): T5LayerNorm()\n",
    "        (norm2): T5LayerNorm()\n",
    "        (dropout1): Dropout(p=0.0, inplace=False)\n",
    "        (dropout2): Dropout(p=0.0, inplace=False)\n",
    "        (dropout3): Dropout(p=0.0, inplace=False)\n",
    "      )\n",
    "    )\n",
    "    (norm): T5LayerNorm()\n",
    "    (dropout1): Dropout(p=0.0, inplace=False)\n",
    "    (dropout2): Dropout(p=0.0, inplace=False)\n",
    "  )\n",
    "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
    ")T5Model(\n",
    "  (token_embeddings): Embedding(32128, 768, padding_idx=0)\n",
    "  (encoder): T5Encoder(\n",
    "    (token_embeddings): Embedding(32128, 768, padding_idx=0)\n",
    "    (layers): ModuleList(\n",
    "      (0): T5Layer(\n",
    "        (self_attn): T5MultiheadAttention(\n",
    "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
    "          (relative_attention_bias): Embedding(32, 12)\n",
    "        )\n",
    "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
    "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
    "        (norm1): T5LayerNorm()\n",
    "        (norm2): T5LayerNorm()\n",
    "        (dropout1): Dropout(p=0.0, inplace=False)\n",
    "        (dropout2): Dropout(p=0.0, inplace=False)\n",
    "        (dropout3): Dropout(p=0.0, inplace=False)\n",
    "      )\n",
    "      (1-11): 11 x T5Layer(\n",
    "        (self_attn): T5MultiheadAttention(\n",
    "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
    "        )\n",
    "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
    "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
    "        (norm1): T5LayerNorm()\n",
    "        (norm2): T5LayerNorm()\n",
    "        (dropout1): Dropout(p=0.0, inplace=False)\n",
    "        (dropout2): Dropout(p=0.0, inplace=False)\n",
    "        (dropout3): Dropout(p=0.0, inplace=False)\n",
    "      )\n",
    "    )\n",
    "    (norm): T5LayerNorm()\n",
    "    (dropout1): Dropout(p=0.0, inplace=False)\n",
    "    (dropout2): Dropout(p=0.0, inplace=False)\n",
    "  )\n",
    "  (decoder): T5Decoder(\n",
    "    (layers): ModuleList(\n",
    "      (0): T5Layer(\n",
    "        (self_attn): T5MultiheadAttention(\n",
    "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
    "          (relative_attention_bias): Embedding(32, 12)\n",
    "        )\n",
    "        (cross_attn): T5MultiheadAttention(\n",
    "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
    "        )\n",
    "        (norm3): T5LayerNorm()\n",
    "        (dropout4): Dropout(p=0.0, inplace=False)\n",
    "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
    "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
    "        (norm1): T5LayerNorm()\n",
    "        (norm2): T5LayerNorm()\n",
    "        (dropout1): Dropout(p=0.0, inplace=False)\n",
    "        (dropout2): Dropout(p=0.0, inplace=False)\n",
    "        (dropout3): Dropout(p=0.0, inplace=False)\n",
    "      )\n",
    "      (1-11): 11 x T5Layer(\n",
    "        (self_attn): T5MultiheadAttention(\n",
    "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
    "        )\n",
    "        (cross_attn): T5MultiheadAttention(\n",
    "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
    "        )\n",
    "        (norm3): T5LayerNorm()\n",
    "        (dropout4): Dropout(p=0.0, inplace=False)\n",
    "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
    "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
    "        (norm1): T5LayerNorm()\n",
    "        (norm2): T5LayerNorm()\n",
    "        (dropout1): Dropout(p=0.0, inplace=False)\n",
    "        (dropout2): Dropout(p=0.0, inplace=False)\n",
    "        (dropout3): Dropout(p=0.0, inplace=False)\n",
    "      )\n",
    "    )\n",
    "    (norm): T5LayerNorm()\n",
    "    (dropout1): Dropout(p=0.0, inplace=False)\n",
    "    (dropout2): Dropout(p=0.0, inplace=False)\n",
    "  )\n",
    "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
    ")```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import CNNDM, WikiText2, WikiText103\n",
    "from functools import partial\n",
    "\n",
    "cnndm_batch_size = 5\n",
    "# cnndm_datapipe = CNNDM(split=\"val\",)\n",
    "# cnndm_datapipe = WikiText2(split=\"test\",)\n",
    "cnndm_datapipe = WikiText103(split=\"test\",)  # takes a lot of time, no output\n",
    "cnndm_datapipe = SQuAD2(split=\"dev\",)  # takes a lot of time, no output\n",
    "task = \"summarize\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.',\n",
       "  'In what country is Normandy located?',\n",
       "  ['France', 'France', 'France', 'France'],\n",
       "  [159, 159, 159, 159]),\n",
       " ('The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.',\n",
       "  'When were the Normans in Normandy?',\n",
       "  ['10th and 11th centuries',\n",
       "   'in the 10th and 11th centuries',\n",
       "   '10th and 11th centuries',\n",
       "   '10th and 11th centuries'],\n",
       "  [94, 87, 94, 94]),\n",
       " ('The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.',\n",
       "  'From which countries did the Norse originate?',\n",
       "  ['Denmark, Iceland and Norway',\n",
       "   'Denmark, Iceland and Norway',\n",
       "   'Denmark, Iceland and Norway',\n",
       "   'Denmark, Iceland and Norway'],\n",
       "  [256, 256, 256, 256]),\n",
       " ('The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.',\n",
       "  'Who was the Norse leader?',\n",
       "  ['Rollo', 'Rollo', 'Rollo', 'Rollo'],\n",
       "  [308, 308, 308, 308]),\n",
       " ('The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.',\n",
       "  'What century did the Normans first gain their separate identity?',\n",
       "  ['10th century', 'the first half of the 10th century', '10th', '10th'],\n",
       "  [671, 649, 671, 671])]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cnndm_datapipe)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11873"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(cnndm_datapipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_prefix(task, x):\n",
    "    return f\"{task}: \" + x[0], x[1]\n",
    "\n",
    "\n",
    "cnndm_datapipe = cnndm_datapipe.map(partial(apply_prefix, task))\n",
    "\n",
    "cnndm_datapipe = cnndm_datapipe.batch(cnndm_batch_size)\n",
    "\n",
    "cnndm_datapipe = cnndm_datapipe.rows2columnar([\"article\", \"abstract\"])\n",
    "\n",
    "cnndm_dataloader = DataLoader(cnndm_datapipe, shuffle=True, batch_size=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
